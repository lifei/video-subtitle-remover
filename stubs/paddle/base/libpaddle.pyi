import datetime
import numpy
import paddle
from _typeshed import Incomplete
from typing import Any, Callable, ClassVar, overload

BFLOAT16: DataType
BOOL: DataType
COMPLEX128: DataType
COMPLEX64: DataType
FLOAT16: DataType
FLOAT32: DataType
FLOAT64: DataType
INT16: DataType
INT32: DataType
INT64: DataType
INT8: DataType
O0: AmpLevel
O1: AmpLevel
O2: AmpLevel
O3: AmpLevel
OD: AmpLevel
UINT16: DataType
UINT32: DataType
UINT64: DataType
UINT8: DataType
UNDEFINED: DataType
kAll: ProfilerState
kAllOpDetail: TracerOption
kAve: EventSortingKey
kCPU: ProfilerState
kCUDA: ProfilerState
kCalls: EventSortingKey
kDefault: EventSortingKey
kDisabled: ProfilerState
kMax: EventSortingKey
kMin: EventSortingKey
kOpDetail: TracerOption
kTotal: EventSortingKey

class AESCipher(Cipher):
    def __init__(self) -> None: ...

class AllreduceOptions:
    reduce_op: ReduceOp
    def __init__(self) -> None: ...

class AmpLevel:
    __members__: ClassVar[dict] = ...  # read-only
    O0: ClassVar[AmpLevel] = ...
    O1: ClassVar[AmpLevel] = ...
    O2: ClassVar[AmpLevel] = ...
    O3: ClassVar[AmpLevel] = ...
    OD: ClassVar[AmpLevel] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __ge__(self, other: object) -> bool: ...
    def __gt__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __le__(self, other: object) -> bool: ...
    def __lt__(self, other: object) -> bool: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class AnalysisConfig:
    class Precision:
        __members__: ClassVar[dict] = ...  # read-only
        Bfloat16: ClassVar[AnalysisConfig.Precision] = ...
        Float32: ClassVar[AnalysisConfig.Precision] = ...
        Half: ClassVar[AnalysisConfig.Precision] = ...
        Int8: ClassVar[AnalysisConfig.Precision] = ...
        __entries: ClassVar[dict] = ...
        def __init__(self, value: int) -> None: ...
        def __eq__(self, other: object) -> bool: ...
        def __hash__(self) -> int: ...
        def __index__(self) -> int: ...
        def __int__(self) -> int: ...
        def __ne__(self, other: object) -> bool: ...
        @property
        def name(self) -> str: ...
        @property
        def value(self) -> int: ...
    Bfloat16: ClassVar[AnalysisConfig.Precision] = ...
    Float32: ClassVar[AnalysisConfig.Precision] = ...
    Half: ClassVar[AnalysisConfig.Precision] = ...
    Int8: ClassVar[AnalysisConfig.Precision] = ...
    @overload
    def __init__(self) -> None: ...
    @overload
    def __init__(self, arg0: AnalysisConfig) -> None: ...
    @overload
    def __init__(self, arg0: str) -> None: ...
    @overload
    def __init__(self, arg0: str, arg1: str) -> None: ...
    def collect_shape_range_info(self, arg0: str) -> None: ...
    def cpu_math_library_num_threads(self) -> int: ...
    def delete_pass(self, arg0: str) -> None: ...
    def disable_glog_info(self) -> None: ...
    def disable_gpu(self) -> None: ...
    def disable_mkldnn(self) -> None: ...
    def disable_onnxruntime(self) -> None: ...
    def dist_config(self, *args, **kwargs): ...
    def enable_custom_device(self, device_type: str, device_id: int = ..., precision: AnalysisConfig.Precision = ...) -> None: ...
    def enable_dlnne(self, min_subgraph_size: int = ..., max_batch_size: int = ..., use_static_batch: bool = ..., weight_share_mode: str = ..., disable_nodes_by_outputs: set[str] = ..., input_shape_dict: dict[str, list[int]] = ..., use_calib_mode: bool = ..., precision_mode: AnalysisConfig.Precision = ...) -> None: ...
    def enable_ipu(self, ipu_device_num: int = ..., ipu_micro_batch_size: int = ..., ipu_enable_pipelining: bool = ..., ipu_batches_per_step: int = ...) -> None: ...
    def enable_lite_engine(self, precision_mode: AnalysisConfig.Precision = ..., zero_copy: bool = ..., passes_filter: list[str] = ..., ops_filter: list[str] = ...) -> None: ...
    def enable_low_precision_io(self, x: bool = ...) -> None: ...
    def enable_memory_optim(self, x: bool = ...) -> None: ...
    def enable_mkldnn(self) -> None: ...
    def enable_mkldnn_bfloat16(self) -> None: ...
    def enable_new_executor(self, x: bool = ...) -> None: ...
    def enable_onnxruntime(self) -> None: ...
    def enable_opencl(self) -> None: ...
    def enable_ort_optimization(self) -> None: ...
    def enable_profile(self) -> None: ...
    def enable_quantizer(self) -> None: ...
    def enable_save_optim_model(self, save_optimized_model: bool = ...) -> None: ...
    def enable_tensorrt_dla(self, dla_core: int = ...) -> None: ...
    def enable_tensorrt_engine(self, workspace_size: int = ..., max_batch_size: int = ..., min_subgraph_size: int = ..., precision_mode: AnalysisConfig.Precision = ..., use_static: bool = ..., use_calib_mode: bool = ..., use_cuda_graph: bool = ...) -> None: ...
    def enable_tensorrt_explicit_quantization(self) -> None: ...
    def enable_tensorrt_inspector(self, inspector_serialize: bool = ...) -> None: ...
    def enable_tensorrt_memory_optim(self, engine_memory_sharing: bool = ..., sharing_identifier: int = ...) -> None: ...
    def enable_tensorrt_varseqlen(self) -> None: ...
    def enable_tuned_tensorrt_dynamic_shape(self, shape_range_info_path: str = ..., allow_build_at_runtime: bool = ...) -> None: ...
    def enable_use_gpu(self, memory_pool_init_size_mb: int, device_id: int = ..., precision_mode: AnalysisConfig.Precision = ...) -> None: ...
    def enable_xpu(self, l3_size: int = ..., l3_locked: bool = ..., conv_autotune: bool = ..., conv_autotune_file: str = ..., transformer_encoder_precision: str = ..., transformer_encoder_adaptive_seqlen: bool = ..., enable_multi_stream: bool = ...) -> None: ...
    def exp_disable_mixed_precision_ops(self, arg0: set[str]) -> None: ...
    def exp_disable_tensorrt_ops(self, arg0: list[str]) -> None: ...
    def exp_enable_mixed_precision_ops(self, arg0: set[str]) -> None: ...
    def exp_enable_use_cutlass(self) -> None: ...
    def fraction_of_gpu_memory_for_pool(self) -> float: ...
    def glog_info_disabled(self) -> bool: ...
    def gpu_device_id(self) -> int: ...
    def ir_optim(self) -> bool: ...
    def lite_engine_enabled(self) -> bool: ...
    def load_ipu_config(self, config_path: str) -> None: ...
    def mark_trt_engine_outputs(self, output_tensor_names: list[str] = ...) -> None: ...
    def memory_pool_init_size_mb(self) -> int: ...
    def mkldnn_enabled(self) -> bool: ...
    def model_dir(self) -> str: ...
    def model_from_memory(self) -> bool: ...
    def nnadapter(self) -> LiteNNAdapterConfig: ...
    def onnxruntime_enabled(self) -> bool: ...
    def params_file(self) -> str: ...
    def pass_builder(self, *args, **kwargs): ...
    def prog_file(self) -> str: ...
    def set_cpu_math_library_num_threads(self, arg0: int) -> None: ...
    def set_dist_config(self, arg0) -> None: ...
    def set_ipu_config(self, ipu_enable_fp16: bool = ..., ipu_replica_num: int = ..., ipu_available_memory_proportion: float = ..., ipu_enable_half_partial: bool = ..., ipu_enable_model_runtime_executor: bool = ...) -> None: ...
    def set_ipu_custom_info(self, ipu_custom_ops_info: list[list[str]] = ..., ipu_custom_patterns: dict[str, bool] = ...) -> None: ...
    def set_mkldnn_op(self, arg0: set[str]) -> None: ...
    @overload
    def set_model(self, arg0: str) -> None: ...
    @overload
    def set_model(self, arg0: str, arg1: str) -> None: ...
    def set_model_buffer(self, arg0: str, arg1: int, arg2: str, arg3: int) -> None: ...
    def set_optim_cache_dir(self, arg0: str) -> None: ...
    def set_params_file(self, arg0: str) -> None: ...
    def set_prog_file(self, arg0: str) -> None: ...
    def set_tensorrt_optimization_level(self, arg0: int) -> None: ...
    def set_trt_dynamic_shape_info(self, min_input_shape: dict[str, list[int]] = ..., max_input_shape: dict[str, list[int]] = ..., optim_input_shape: dict[str, list[int]] = ..., disable_trt_plugin_fp16: bool = ...) -> None: ...
    def set_xpu_config(self, arg0: XpuConfig) -> None: ...
    def set_xpu_device_id(self, device_id: int = ...) -> None: ...
    def shape_range_info_collected(self) -> bool: ...
    def shape_range_info_path(self) -> str: ...
    def specify_input_name(self) -> bool: ...
    def summary(self) -> str: ...
    def switch_ir_debug(self, x: int = ...) -> None: ...
    def switch_ir_optim(self, x: int = ...) -> None: ...
    def switch_specify_input_names(self, x: bool = ...) -> None: ...
    def switch_use_feed_fetch_ops(self, x: int = ...) -> None: ...
    def tensorrt_dla_enabled(self) -> bool: ...
    def tensorrt_dynamic_shape_enabled(self) -> bool: ...
    def tensorrt_engine_enabled(self) -> bool: ...
    def tensorrt_explicit_quantization_enabled(self) -> bool: ...
    def tensorrt_inspector_enabled(self) -> bool: ...
    def tensorrt_optimization_level(self) -> int: ...
    def tensorrt_precision_mode(self) -> AnalysisConfig.Precision: ...
    def tensorrt_varseqlen_enabled(self) -> bool: ...
    def to_native_config(self) -> NativeConfig: ...
    def trt_allow_build_at_runtime(self) -> bool: ...
    def tuned_tensorrt_dynamic_shape(self) -> bool: ...
    def use_feed_fetch_ops_enabled(self) -> bool: ...
    def use_gpu(self) -> bool: ...
    def use_opencl(self) -> bool: ...
    def use_xpu(self) -> bool: ...
    def xpu_config(self) -> XpuConfig: ...
    def xpu_device_id(self) -> int: ...

class AnalysisPredictor(PaddlePredictor):
    def __init__(self, arg0: AnalysisConfig) -> None: ...
    def SaveOptimModel(self, dir: str) -> None: ...
    def analysis_argument(self, *args, **kwargs): ...
    def clear_intermediate_tensor(self) -> None: ...
    def clone(self) -> PaddlePredictor: ...
    def create_feed_fetch_var(self, arg0: _Scope) -> None: ...
    def get_input_names(self) -> list[str]: ...
    def get_input_tensor(self, *args, **kwargs): ...
    def get_input_tensor_shape(self) -> dict[str, list[int]]: ...
    def get_output_names(self) -> list[str]: ...
    def get_output_tensor(self, *args, **kwargs): ...
    def get_serialized_program(self) -> str: ...
    def init(self, arg0: _Scope, arg1: ProgramDesc) -> bool: ...
    def mkldnn_quantize(self) -> bool: ...
    def optimize_inference_program(self) -> None: ...
    def prepare_argument(self) -> None: ...
    def prepare_feed_fetch(self) -> None: ...
    def program(self) -> ProgramDesc: ...
    def run(self, arg0: list[PaddleTensor]) -> list[PaddleTensor]: ...
    def scope(self) -> _Scope: ...
    def try_shrink_memory(self) -> int: ...
    def zero_copy_run(self) -> bool: ...

class AttrType:
    __members__: ClassVar[dict] = ...  # read-only
    BLOCK: ClassVar[AttrType] = ...
    BLOCKS: ClassVar[AttrType] = ...
    BOOL: ClassVar[AttrType] = ...
    BOOLS: ClassVar[AttrType] = ...
    FLOAT: ClassVar[AttrType] = ...
    FLOAT64: ClassVar[AttrType] = ...
    FLOAT64S: ClassVar[AttrType] = ...
    FLOATS: ClassVar[AttrType] = ...
    INT: ClassVar[AttrType] = ...
    INTS: ClassVar[AttrType] = ...
    LONG: ClassVar[AttrType] = ...
    LONGS: ClassVar[AttrType] = ...
    SCALAR: ClassVar[AttrType] = ...
    SCALARS: ClassVar[AttrType] = ...
    STRING: ClassVar[AttrType] = ...
    STRINGS: ClassVar[AttrType] = ...
    VAR: ClassVar[AttrType] = ...
    VARS: ClassVar[AttrType] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class BarrierOptions:
    device_id: int
    def __init__(self) -> None: ...

class BlockDesc:
    def __init__(self, *args, **kwargs) -> None: ...
    def all_vars(self, *args, **kwargs): ...
    def append_op(self, *args, **kwargs): ...
    def find_var(self, *args, **kwargs): ...
    def find_var_recursive(self, *args, **kwargs): ...
    def get_forward_block_idx(self) -> int: ...
    def has_var(self, arg0: bytes) -> bool: ...
    def has_var_recursive(self, arg0: bytes) -> bool: ...
    def op(self, *args, **kwargs): ...
    def op_size(self) -> int: ...
    def serialize_to_string(self) -> bytes: ...
    def set_parent_idx(self, arg0: int) -> None: ...
    def var(self, *args, **kwargs): ...
    @property
    def id(self) -> int: ...
    @property
    def parent(self) -> int: ...

class BoxPS:
    def __init__(self, arg0) -> None: ...
    def begin_pass(self) -> None: ...
    def end_pass(self, arg0: bool) -> None: ...
    def load_into_memory(self) -> None: ...
    def preload_into_memory(self) -> None: ...
    def set_date(self, arg0: int, arg1: int, arg2: int) -> None: ...
    def slots_shuffle(self, arg0: set[str]) -> None: ...
    def wait_feed_pass_done(self) -> None: ...

class BroadcastOptions:
    source_rank: int
    source_root: int
    def __init__(self) -> None: ...

class CPUPlace:
    def __init__(self) -> None: ...

class CUDAEvent:
    def __init__(self, enable_timing: bool = ..., blocking: bool = ..., interprocess: bool = ...) -> None: ...

class CUDAPinnedPlace:
    def __init__(self) -> None: ...

class CUDAPlace:
    def __init__(self, arg0: int) -> None: ...

class CUDAStream:
    @overload
    def __init__(self, device=..., priority: int = ...) -> None: ...
    @overload
    def __init__(self, device: int = ..., priority: int = ...) -> None: ...
    @overload
    def __init__(self) -> None: ...

class Cipher:
    def __init__(self) -> None: ...
    def decrypt(self, arg0: str, arg1: str) -> bytes: ...
    def decrypt_from_file(self, arg0: str, arg1: str) -> bytes: ...
    def encrypt(self, arg0: str, arg1: str) -> bytes: ...
    def encrypt_to_file(self, arg0: str, arg1: str, arg2: str) -> None: ...

class CipherFactory:
    def __init__(self) -> None: ...
    @staticmethod
    def create_cipher(config_file: str = ...) -> Cipher: ...

class CipherUtils:
    def __init__(self, *args, **kwargs) -> None: ...
    @staticmethod
    def gen_key(arg0: int) -> bytes: ...
    @staticmethod
    def gen_key_to_file(arg0: int, arg1: str) -> bytes: ...
    @staticmethod
    def read_key_from_file(arg0: str) -> bytes: ...

class CommContextManager:
    def __init__(self, *args, **kwargs) -> None: ...
    @staticmethod
    def set_device_id(arg0: int) -> None: ...
    def set_store(self, arg0: Store) -> None: ...

class CostData:
    def __init__(self) -> None: ...
    def get_op_time_ms(self, arg0: int) -> float: ...
    def get_whole_time_ms(self) -> float: ...

class CostInfo:
    def __init__(self) -> None: ...
    def device_memory_bytes(self) -> int: ...
    def total_time(self) -> float: ...

class CostModel:
    def __init__(self) -> None: ...
    def profile_measure(self, arg0: object, arg1: object, arg2: str, arg3: list[str]) -> CostData: ...

class CpuPassStrategy(PassStrategy):
    @overload
    def __init__(self) -> None: ...
    @overload
    def __init__(self, arg0: CpuPassStrategy) -> None: ...
    def enable_cudnn(self) -> None: ...
    def enable_mkldnn(self) -> None: ...
    def enable_mkldnn_bfloat16(self) -> None: ...
    def enable_mkldnn_quantizer(self) -> None: ...

class CustomDeviceEvent:
    @overload
    def __init__(self, device, enable_timing: bool = ..., blocking: bool = ..., interprocess: bool = ...) -> None: ...
    @overload
    def __init__(self, device: str, device_id: int = ..., enable_timing: bool = ..., blocking: bool = ..., interprocess: bool = ...) -> None: ...
    def query(self) -> None: ...
    @overload
    def record(self, arg0: CustomDeviceStream) -> None: ...
    @overload
    def record(self) -> Any: ...
    @overload
    def synchronize(self) -> None: ...
    @overload
    def synchronize(self) -> Any: ...
    @property
    def place(self) -> None: ...
    @property
    def raw_event(self) -> None: ...

class CustomDeviceStream:
    @overload
    def __init__(self, device, priority: int = ..., blocking: bool = ...) -> None: ...
    @overload
    def __init__(self, device: str, device_id: int = ..., priority: int = ..., blocking: bool = ...) -> None: ...
    @overload
    def query(self) -> None: ...
    @overload
    def query(self) -> Any: ...
    @overload
    def record_event(self, event=...) -> None: ...
    @overload
    def record_event(self) -> Any: ...
    @overload
    def synchronize(self) -> None: ...
    @overload
    def synchronize(self) -> Any: ...
    @overload
    def wait_event(self, arg0) -> None: ...
    @overload
    def wait_event(self, event) -> Any: ...
    @overload
    def wait_stream(self, arg0: CustomDeviceStream) -> None: ...
    @overload
    def wait_stream(self, s2) -> Any: ...
    @property
    def place(self) -> None: ...
    @property
    def raw_stream(self) -> None: ...

class CustomPlace:
    def __init__(self, arg0: str, arg1: int) -> None: ...
    def get_device_id(self) -> int: ...
    def get_device_type(self) -> str: ...

class DataType:
    __members__: ClassVar[dict] = ...  # read-only
    BFLOAT16: ClassVar[DataType] = ...
    BOOL: ClassVar[DataType] = ...
    COMPLEX128: ClassVar[DataType] = ...
    COMPLEX64: ClassVar[DataType] = ...
    FLOAT16: ClassVar[DataType] = ...
    FLOAT32: ClassVar[DataType] = ...
    FLOAT64: ClassVar[DataType] = ...
    INT16: ClassVar[DataType] = ...
    INT32: ClassVar[DataType] = ...
    INT64: ClassVar[DataType] = ...
    INT8: ClassVar[DataType] = ...
    UINT16: ClassVar[DataType] = ...
    UINT32: ClassVar[DataType] = ...
    UINT64: ClassVar[DataType] = ...
    UINT8: ClassVar[DataType] = ...
    UNDEFINED: ClassVar[DataType] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class Dataset:
    def __init__(self, arg0: str) -> None: ...
    def clear_sample_state(self) -> None: ...
    def create_channel(self) -> None: ...
    def create_preload_readers(self) -> None: ...
    def create_readers(self) -> None: ...
    def destroy_preload_readers(self) -> None: ...
    def destroy_readers(self) -> None: ...
    def dump_sample_neighbors(self, arg0: str) -> None: ...
    def dump_walk_path(self, arg0: str, arg1: int) -> None: ...
    def dynamic_adjust_channel_num(self, arg0: int, arg1: bool) -> None: ...
    def dynamic_adjust_readers_num(self, arg0: int) -> None: ...
    def enable_pv_merge(self) -> bool: ...
    def generate_local_tables_unlock(self, arg0: int, arg1: int, arg2: int, arg3: int, arg4: int) -> None: ...
    def get_data_feed_desc(self, *args, **kwargs): ...
    def get_download_cmd(self) -> str: ...
    def get_epoch_finish(self) -> bool: ...
    def get_filelist(self) -> list[str]: ...
    def get_fleet_send_batch_size(self) -> int: ...
    def get_hdfs_config(self) -> tuple[str, str]: ...
    def get_memory_data_size(self) -> int: ...
    def get_pass_id(self) -> int: ...
    def get_pv_data_size(self) -> int: ...
    def get_shuffle_data_size(self) -> int: ...
    def get_thread_num(self) -> int: ...
    def get_trainer_num(self) -> int: ...
    def global_shuffle(self, arg0: int) -> None: ...
    def load_into_memory(self) -> None: ...
    def local_shuffle(self) -> None: ...
    def merge_by_lineid(self) -> None: ...
    def postprocess_instance(self) -> None: ...
    def preload_into_memory(self) -> None: ...
    def preprocess_instance(self) -> None: ...
    def register_client2client_msg_handler(self) -> None: ...
    def release_memory(self) -> None: ...
    def set_current_phase(self, arg0: int) -> None: ...
    def set_data_feed_desc(self, arg0: str) -> None: ...
    def set_download_cmd(self, arg0: str) -> None: ...
    def set_enable_pv_merge(self, arg0: bool) -> None: ...
    def set_fea_eval(self, arg0: bool, arg1: int) -> None: ...
    def set_filelist(self, arg0: list[str]) -> None: ...
    def set_fleet_send_batch_size(self, arg0: int) -> None: ...
    def set_fleet_send_sleep_seconds(self, arg0: int) -> None: ...
    def set_generate_unique_feasigns(self, arg0: bool) -> None: ...
    def set_gpu_graph_mode(self, arg0: int) -> None: ...
    def set_hdfs_config(self, arg0: str, arg1: str) -> None: ...
    def set_merge_by_lineid(self, arg0: int) -> None: ...
    def set_merge_by_sid(self, arg0: bool) -> None: ...
    def set_parse_content(self, arg0: bool) -> None: ...
    def set_parse_ins_id(self, arg0: bool) -> None: ...
    def set_parse_logkey(self, arg0: bool) -> None: ...
    def set_pass_id(self, arg0: int) -> None: ...
    def set_preload_thread_num(self, arg0: int) -> None: ...
    def set_queue_num(self, arg0: int) -> None: ...
    def set_shuffle_by_uid(self, arg0: bool) -> None: ...
    def set_thread_num(self, arg0: int) -> None: ...
    def set_trainer_num(self, arg0: int) -> None: ...
    def slots_shuffle(self, arg0: set[str]) -> None: ...
    def tdm_sample(self, arg0: str, arg1: str, arg2: list[int], arg3: int, arg4: bool, arg5: int, arg6: int) -> None: ...
    def wait_preload_done(self) -> None: ...

class DependType:
    __members__: ClassVar[dict] = ...  # read-only
    LOOP: ClassVar[DependType] = ...
    NORMAL: ClassVar[DependType] = ...
    STOP_LOOP: ClassVar[DependType] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class Device:
    capability: DeviceCapability
    def __init__(self, global_id: int, local_id: int, machine_id: int, type: str) -> None: ...
    def __eq__(self, arg0: Device) -> bool: ...
    def __ne__(self, arg0: Device) -> bool: ...
    @property
    def global_id(self) -> int: ...
    @property
    def local_id(self) -> int: ...
    @property
    def machine_id(self) -> int: ...
    @property
    def type(self) -> str: ...

class DeviceCapability:
    dflops: float
    memory: float
    rate: float
    sflops: float
    def __init__(self) -> None: ...

class DeviceContext:
    def __init__(self, *args, **kwargs) -> None: ...
    @overload
    @staticmethod
    def create(arg0) -> DeviceContext: ...
    @overload
    @staticmethod
    def create(arg0) -> DeviceContext: ...
    @overload
    @staticmethod
    def create(arg0) -> DeviceContext: ...
    @overload
    @staticmethod
    def create(arg0) -> DeviceContext: ...
    @overload
    @staticmethod
    def create(arg0) -> DeviceContext: ...

class DeviceMesh:
    def __init__(self, name: str, shape: list[int], device_ids: list[int], dim_names: list[str]) -> None: ...
    def add_device(self, arg0: Device) -> None: ...
    def add_link(self, arg0: Link) -> None: ...
    def contains(self, arg0: int) -> bool: ...
    def device(self, arg0: int) -> Device: ...
    @overload
    def dim_size(self, arg0: int) -> int: ...
    @overload
    def dim_size(self, arg0: str) -> int: ...
    def empty(self) -> bool: ...
    def link(self, arg0: int, arg1: int) -> Link: ...
    def machine(self, arg0: int) -> Machine: ...
    def __copy__(self): ...
    def __deepcopy__(self): ...
    def __eq__(self, arg0: DeviceMesh) -> bool: ...
    def __ne__(self, arg0: DeviceMesh) -> bool: ...
    @property
    def device_ids(self) -> list[int]: ...
    @property
    def device_type(self) -> str: ...
    @property
    def devices(self) -> dict[int, Device]: ...
    @property
    def dim_names(self) -> list[str]: ...
    @property
    def links(self) -> dict[int, dict[int, Link]]: ...
    @property
    def machines(self) -> dict[int, Machine]: ...
    @property
    def name(self) -> str: ...
    @property
    def ndim(self) -> int: ...
    @property
    def shape(self) -> list[int]: ...
    @property
    def size(self) -> int: ...

class DevicePythonNode:
    block_x: int
    block_y: int
    block_z: int
    blocks_per_sm: float
    context_id: int
    correlation_id: int
    device_id: int
    end_ns: int
    grid_x: int
    grid_y: int
    grid_z: int
    name: str
    num_bytes: int
    occupancy: float
    registers_per_thread: int
    shared_memory: int
    start_ns: int
    stream_id: int
    type: Incomplete
    value: int
    warps_per_sm: float
    def __init__(self) -> None: ...

class DeviceType:
    __members__: ClassVar[dict] = ...  # read-only
    CPU: ClassVar[DeviceType] = ...
    CUDA: ClassVar[DeviceType] = ...
    XPU: ClassVar[DeviceType] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __and__(self, other: object) -> object: ...
    def __eq__(self, other: object) -> bool: ...
    def __ge__(self, other: object) -> bool: ...
    def __gt__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __invert__(self) -> object: ...
    def __le__(self, other: object) -> bool: ...
    def __lt__(self, other: object) -> bool: ...
    def __ne__(self, other: object) -> bool: ...
    def __or__(self, other: object) -> object: ...
    def __rand__(self, other: object) -> object: ...
    def __ror__(self, other: object) -> object: ...
    def __rxor__(self, other: object) -> object: ...
    def __xor__(self, other: object) -> object: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class DistConfig:
    def __init__(self) -> None: ...
    def carrier_id(self) -> str: ...
    def comm_init_config(self) -> str: ...
    def current_endpoint(self) -> str: ...
    def enable_dist_model(self, arg0: bool) -> None: ...
    def nranks(self) -> int: ...
    def rank(self) -> int: ...
    def set_carrier_id(self, arg0: str) -> None: ...
    def set_comm_init_config(self, arg0: str) -> None: ...
    def set_endpoints(self, arg0: list[str], arg1: str) -> None: ...
    def set_ranks(self, arg0: int, arg1: int) -> None: ...
    def trainer_endpoints(self) -> list[str]: ...
    def use_dist_model(self) -> bool: ...

class DistModel:
    def __init__(self, arg0: DistModelConfig) -> None: ...
    def init(self) -> bool: ...
    def run(self, *args, **kwargs): ...

class DistModelConfig:
    current_endpoint: str
    device_id: int
    enable_timer: bool
    local_rank: int
    model_dir: str
    nranks: int
    place: str
    program_desc: ProgramDesc
    rank_to_ring_ids: dict[int, list[int]]
    ring_id_to_ranks: dict[int, list[int]]
    scope: _Scope
    trainer_endpoints: list[str]
    def __init__(self) -> None: ...

class DistModelDataBuf:
    @overload
    def __init__(self, arg0: int) -> None: ...
    @overload
    def __init__(self, arg0: list[float]) -> None: ...
    @overload
    def __init__(self, arg0: numpy.ndarray[numpy.int32]) -> None: ...
    @overload
    def __init__(self, arg0: numpy.ndarray[numpy.int64]) -> None: ...
    @overload
    def __init__(self, arg0: numpy.ndarray[numpy.float32]) -> None: ...
    @overload
    def __init__(self, arg0: numpy.ndarray[float16]) -> None: ...
    def length(self) -> int: ...
    @overload
    def reset(self, arg0: list[float]) -> None: ...
    @overload
    def reset(self, arg0: numpy.ndarray[numpy.int32]) -> None: ...
    @overload
    def reset(self, arg0: numpy.ndarray[numpy.int64]) -> None: ...
    @overload
    def reset(self, arg0: numpy.ndarray[numpy.float32]) -> None: ...
    @overload
    def reset(self, arg0: numpy.ndarray[float16]) -> None: ...
    def tolist(self, arg0: str) -> list: ...

class DistModelDataType:
    __members__: ClassVar[dict] = ...  # read-only
    FLOAT16: ClassVar[DistModelDataType] = ...
    FLOAT32: ClassVar[DistModelDataType] = ...
    INT32: ClassVar[DistModelDataType] = ...
    INT64: ClassVar[DistModelDataType] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class DistModelTensor:
    data: DistModelDataBuf
    dtype: Incomplete
    lod: list[list[int]]
    name: str
    shape: list[int]
    @overload
    def __init__(self) -> None: ...
    @overload
    def __init__(self, data: numpy.ndarray[numpy.int32], name: str = ..., lod: list[list[int]] = ..., copy: bool = ...) -> None: ...
    @overload
    def __init__(self, data: numpy.ndarray[numpy.int64], name: str = ..., lod: list[list[int]] = ..., copy: bool = ...) -> None: ...
    @overload
    def __init__(self, data: numpy.ndarray[numpy.float32], name: str = ..., lod: list[list[int]] = ..., copy: bool = ...) -> None: ...
    @overload
    def __init__(self, data: numpy.ndarray[float16], name: str = ..., lod: list[list[int]] = ..., copy: bool = ...) -> None: ...
    def as_ndarray(self) -> numpy.ndarray: ...

class DistTensorSpec:
    shape: list[int]
    @overload
    def __init__(self) -> None: ...
    @overload
    def __init__(self, arg0: DistTensorSpec) -> None: ...
    @overload
    def __init__(self, arg0: list[int], arg1: TensorDistAttr) -> None: ...
    def dims_mapping(self) -> list[int]: ...
    def process_mesh(self) -> ProcessMesh: ...
    def set_dims_mapping(self, arg0: list[int]) -> None: ...
    def set_process_mesh(self, arg0: ProcessMesh) -> None: ...
    def __copy__(self) -> DistTensorSpec: ...
    def __deepcopy__(self, memo: dict) -> DistTensorSpec: ...

class EOFException(Exception): ...

class EagerReducer:
    def __init__(self, arg0: object, arg1: list[list[int]], arg2: list[bool], arg3: ProcessGroup, arg4: list[int], arg5: bool) -> None: ...
    def prepare_for_backward(self, tensors: object) -> None: ...

class EnforceNotMet(Exception): ...

class EventSortingKey:
    __members__: ClassVar[dict] = ...  # read-only
    __entries: ClassVar[dict] = ...
    kAve: ClassVar[EventSortingKey] = ...
    kCalls: ClassVar[EventSortingKey] = ...
    kDefault: ClassVar[EventSortingKey] = ...
    kMax: ClassVar[EventSortingKey] = ...
    kMin: ClassVar[EventSortingKey] = ...
    kTotal: ClassVar[EventSortingKey] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __ge__(self, other: object) -> bool: ...
    def __gt__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __le__(self, other: object) -> bool: ...
    def __lt__(self, other: object) -> bool: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class Executor:
    def __init__(self, arg0) -> None: ...
    def close(self) -> None: ...
    def create_variables(self, arg0, arg1: _Scope, arg2: int) -> None: ...
    def init_for_dataset(self, arg0, arg1: str, arg2: _Scope, arg3) -> TrainerBase: ...
    def prepare(self, arg0, arg1: int, arg2: list[str], arg3: bool) -> ExecutorPrepareContext: ...
    def release_trainer(self, arg0: TrainerBase) -> None: ...
    def run(self, arg0, arg1: _Scope, arg2: int, arg3: bool, arg4: bool, arg5: list[str]) -> None: ...
    @overload
    def run_from_dataset(self, arg0: TrainerBase) -> None: ...
    @overload
    def run_from_dataset(self, arg0: TrainerBase) -> None: ...
    @overload
    def run_prepared_ctx(self, arg0: ExecutorPrepareContext, arg1: _Scope, arg2, arg3, arg4: bool, arg5: bool, arg6: str, arg7: str) -> None: ...
    @overload
    def run_prepared_ctx(self, arg0: ExecutorPrepareContext, arg1: _Scope, arg2: bool, arg3: bool, arg4: bool) -> None: ...

class ExecutorPrepareContext:
    def __init__(self, arg0, arg1: int) -> None: ...

class FetchList:
    def __init__(self, *args, **kwargs) -> None: ...
    @overload
    def append(self, var) -> None: ...
    @overload
    def append(self, var: LoDTensorArray) -> None: ...

class FetchUnmergedList:
    def __init__(self, *args, **kwargs) -> None: ...

class Fleet:
    def __init__(self) -> None: ...
    def cache_shuffle(self, arg0: int, arg1: str, arg2: int, arg3: float) -> None: ...
    def clear_model(self) -> None: ...
    def clear_one_table(self, arg0: int) -> None: ...
    def client_flush(self) -> None: ...
    def confirm(self) -> None: ...
    def copy_table(self, arg0: int, arg1: int) -> int: ...
    def copy_table_by_feasign(self, arg0: int, arg1: int, arg2: list[int]) -> int: ...
    def create_client2client_connection(self) -> None: ...
    def finalize_worker(self) -> None: ...
    def gather_clients(self, arg0: list[int]) -> None: ...
    def gather_servers(self, arg0: list[int], arg1: int) -> None: ...
    def get_cache_threshold(self, arg0: int) -> float: ...
    def get_clients_info(self) -> list[int]: ...
    def init_model(self, arg0: _Scope, arg1: int, arg2: list[str]) -> None: ...
    def init_server(self, arg0: str, arg1: int) -> None: ...
    def init_worker(self, arg0: str, arg1: list[int], arg2: int, arg3: int) -> None: ...
    def load_from_paddle_model(self, arg0: _Scope, arg1: int, arg2: list[str], arg3: str, arg4: str, arg5: list[str], arg6: bool) -> None: ...
    def load_model(self, arg0: str, arg1: int) -> None: ...
    def load_model_one_table(self, arg0: int, arg1: str, arg2: int) -> None: ...
    def load_table_with_whitelist(self, arg0: int, arg1: str, arg2: int) -> None: ...
    def print_table_stat(self, arg0: int, arg1: int, arg2: int) -> None: ...
    def pull_dense(self, arg0: _Scope, arg1: int, arg2: list[str]) -> None: ...
    def push_dense(self, arg0: _Scope, arg1: int, arg2: list[str]) -> None: ...
    def revert(self) -> None: ...
    @overload
    def run_server(self) -> int: ...
    @overload
    def run_server(self, arg0: str, arg1: int) -> int: ...
    def save_cache(self, arg0: int, arg1: str, arg2: int) -> int: ...
    def save_model(self, arg0: str, arg1: int) -> None: ...
    def save_model_one_table(self, arg0: int, arg1: str, arg2: int) -> None: ...
    def save_model_one_table_with_prefix(self, arg0: int, arg1: str, arg2: int, arg3: str) -> None: ...
    def save_model_with_whitelist(self, arg0: int, arg1: str, arg2: int, arg3: str) -> int: ...
    def save_multi_table_one_path(self, arg0: list[int], arg1: str, arg2: int) -> None: ...
    def set_client2client_config(self, arg0: int, arg1: int, arg2: int) -> None: ...
    def set_date(self, arg0: int, arg1: str) -> None: ...
    def set_file_num_one_shard(self, arg0: int, arg1: int) -> None: ...
    def set_pull_local_thread_num(self, arg0: int) -> None: ...
    def shrink_dense_table(self, arg0: int, arg1: _Scope, arg2: list[str], arg3: float, arg4: int) -> None: ...
    def shrink_sparse_table(self, arg0: int) -> None: ...
    def stop_server(self) -> None: ...

class FleetExecutor:
    def __init__(self, arg0: str) -> None: ...
    def init(self, arg0: str, arg1: ProgramDesc, arg2: _Scope, arg3, arg4: int, arg5, arg6: dict[int, int], arg7: list[str], arg8: list[_Scope]) -> None: ...
    def run(self, arg0: str) -> None: ...

class Function:
    def __init__(self, *args, **kwargs) -> None: ...

class FunctionInfo:
    def __init__(self, *args, **kwargs) -> None: ...
    def input_names(self) -> list[str]: ...
    def name(self) -> str: ...
    def output_names(self) -> list[str]: ...

class GatherOptions:
    root_rank: int
    def __init__(self) -> None: ...

class Generator:
    def __init__(self) -> None: ...
    def get_state(self) -> GeneratorState: ...
    def initial_seed(self) -> int: ...
    def manual_seed(self, arg0: int) -> Generator: ...
    def random(self) -> int: ...
    def seed(self) -> int: ...
    def set_state(self, arg0: GeneratorState) -> None: ...

class GeneratorState:
    def __init__(self, *args, **kwargs) -> None: ...
    def current_seed(self) -> int: ...

class GlobalVarGetterSetterRegistry:
    def __init__(self, *args, **kwargs) -> None: ...
    def get(self, key: str, default: object = ...) -> object: ...
    def get_default(self, key: str) -> object: ...
    def is_public(self, arg0: str) -> bool: ...
    def keys(self) -> set[str]: ...
    def __contains__(self, arg0: str) -> bool: ...
    def __getitem__(self, arg0: str) -> object: ...
    def __setitem__(self, arg0: str, arg1: object) -> None: ...

class Gloo:
    def __init__(self) -> None: ...
    @overload
    def all_gather(self, arg0: int) -> list[int]: ...
    @overload
    def all_gather(self, arg0: int) -> list[int]: ...
    @overload
    def all_gather(self, arg0: float) -> list[float]: ...
    @overload
    def all_gather(self, arg0: float) -> list[float]: ...
    @overload
    def all_reduce(self, arg0: list[int], arg1: str) -> list[int]: ...
    @overload
    def all_reduce(self, arg0: list[int], arg1: str) -> list[int]: ...
    @overload
    def all_reduce(self, arg0: list[float], arg1: str) -> list[float]: ...
    @overload
    def all_reduce(self, arg0: list[float], arg1: str) -> list[float]: ...
    def barrier(self) -> None: ...
    def init(self) -> None: ...
    def rank(self) -> int: ...
    def set_hdfs_store(self, arg0: str, arg1: str, arg2: str) -> None: ...
    def set_http_store(self, arg0: str, arg1: int, arg2: str) -> None: ...
    def set_iface(self, arg0: str) -> None: ...
    def set_prefix(self, arg0: str) -> None: ...
    def set_rank(self, arg0: int) -> None: ...
    def set_size(self, arg0: int) -> None: ...
    def set_timeout_seconds(self, arg0: int, arg1: int) -> None: ...
    def size(self) -> int: ...

class GpuPassStrategy(PassStrategy):
    @overload
    def __init__(self) -> None: ...
    @overload
    def __init__(self, arg0: GpuPassStrategy) -> None: ...
    def enable_cudnn(self) -> None: ...
    def enable_mkldnn(self) -> None: ...
    def enable_mkldnn_bfloat16(self) -> None: ...
    def enable_mkldnn_quantizer(self) -> None: ...

class GradNodeBase:
    def __init__(self, *args, **kwargs) -> None: ...
    def input_meta(self, *args, **kwargs): ...
    def name(self) -> str: ...
    def node_ptr(self) -> int: ...
    def output_meta(self, *args, **kwargs): ...
    @property
    def next_functions(self) -> list[GradNodeBase]: ...

class Graph:
    @overload
    def __init__(self, arg0: ProgramDesc) -> None: ...
    @overload
    def __init__(self, arg0: ProgramDesc, arg1: int, arg2: int) -> None: ...
    def clone(self) -> Graph: ...
    def create_control_dep_var(self, *args, **kwargs): ...
    def create_empty_node(self, *args, **kwargs): ...
    def create_op_node(self, *args, **kwargs): ...
    def create_var_node(self, *args, **kwargs): ...
    def erase(self, arg0: str) -> None: ...
    def get_bool(self, arg0: str) -> bool: ...
    def get_double(self, arg0: str) -> float: ...
    def get_float(self, arg0: str) -> float: ...
    def get_int(self, arg0: str) -> int: ...
    def get_marked_nodes(self, *args, **kwargs): ...
    def get_string(self, arg0: str) -> str: ...
    def get_sub_graph(self, arg0: int) -> Graph: ...
    def has(self, arg0: str) -> bool: ...
    def nodes(self, *args, **kwargs): ...
    def origin_program_desc(self) -> ProgramDesc: ...
    def release_nodes(self, *args, **kwargs): ...
    def remove_node(self, *args, **kwargs): ...
    def resolve_hazard(self, arg0) -> None: ...
    def retrieve_node(self, *args, **kwargs): ...
    @overload
    def set(self, arg0: str, arg1: bool) -> None: ...
    @overload
    def set(self, arg0: str, arg1: int) -> None: ...
    @overload
    def set(self, arg0: str, arg1: str) -> None: ...
    @overload
    def set(self, arg0: str, arg1: float) -> None: ...
    @overload
    def set(self, arg0: str, arg1: float) -> None: ...
    @overload
    def set(self, arg0: str, arg1) -> None: ...
    @overload
    def set(self, arg0: str, arg1: set[str]) -> None: ...
    def set_not_owned(self, arg0: str, arg1: _Scope) -> None: ...
    def sub_graph_size(self) -> int: ...

class HostPythonNode:
    attributes: dict[str, Variant]
    callstack: str
    children_node: list[HostPythonNode]
    correlation_id: int
    device_node: list[DevicePythonNode]
    dtypes: dict[str, list[str]]
    end_ns: int
    input_shapes: dict[str, list[list[int]]]
    mem_node: list[MemPythonNode]
    name: str
    op_id: int
    process_id: int
    runtime_node: list[HostPythonNode]
    start_ns: int
    thread_id: int
    type: Incomplete
    def __init__(self) -> None: ...

class IPUPlace:
    def __init__(self) -> None: ...

class InternalUtils:
    def __init__(self, *args, **kwargs) -> None: ...
    @staticmethod
    def disable_tensorrt_half_ops(arg0: AnalysisConfig, arg1: set[str]) -> None: ...
    @staticmethod
    def set_transformer_maskid(arg0: AnalysisConfig, arg1: str) -> None: ...
    @staticmethod
    def set_transformer_posid(arg0: AnalysisConfig, arg1: str) -> None: ...

class IterableDatasetWrapper:
    def __init__(self, arg0: Dataset, arg1: list[str], arg2: list[Place], arg3: int, arg4: bool) -> None: ...

class Job:
    def __init__(self, type: str) -> None: ...
    def micro_batch_id(self) -> int: ...
    def set_micro_batch_id(self, arg0: int) -> None: ...
    def set_skip_gc_vars(self, arg0: set[str]) -> None: ...
    def type(self) -> str: ...

class Layer:
    def __init__(self, *args, **kwargs) -> None: ...
    def function(self, *args, **kwargs): ...
    def function_info(self, *args, **kwargs): ...
    def function_names(self) -> list[str]: ...

class Link:
    capability: LinkCapability
    def __init__(self, source_id: int, target_id: int, type: str) -> None: ...
    def __eq__(self, arg0: Link) -> bool: ...
    def __ne__(self, arg0: Link) -> bool: ...
    @property
    def source_id(self) -> int: ...
    @property
    def target_id(self) -> int: ...
    @property
    def type(self) -> str: ...

class LinkCapability:
    bandwidth: int
    latency: int
    def __init__(self) -> None: ...

class LiteNNAdapterConfig:
    def __init__(self, *args, **kwargs) -> None: ...
    def disable(self) -> LiteNNAdapterConfig: ...
    def enable(self) -> LiteNNAdapterConfig: ...
    def set_context_properties(self, arg0: str) -> LiteNNAdapterConfig: ...
    def set_device_names(self, arg0: list[str]) -> LiteNNAdapterConfig: ...
    def set_model_cache_buffers(self, arg0: str, arg1: list[str]) -> LiteNNAdapterConfig: ...
    def set_model_cache_dir(self, arg0: str) -> LiteNNAdapterConfig: ...
    def set_subgraph_partition_config_buffer(self, arg0: str) -> LiteNNAdapterConfig: ...
    def set_subgraph_partition_config_path(self, arg0: str) -> LiteNNAdapterConfig: ...

class LoDTensor:
    @overload
    def __init__(self, arg0: list[list[int]]) -> None: ...
    @overload
    def __init__(self) -> None: ...
    @overload
    def has_valid_recursive_sequence_lengths(self) -> bool: ...
    @overload
    def has_valid_recursive_sequence_lengths(self) -> Any: ...
    @overload
    def lod(self) -> list[list[int]]: ...
    @overload
    def lod(self) -> Any: ...
    @overload
    def recursive_sequence_lengths(self) -> list[list[int]]: ...
    @overload
    def recursive_sequence_lengths(self) -> Any: ...
    @overload
    def set(self, array: object, place: CPUPlace, zero_copy: bool = ...) -> None: ...
    @overload
    def set(self, array: object, place: CustomPlace, zero_copy: bool = ...) -> None: ...
    @overload
    def set(self, array: object, place: XPUPlace, zero_copy: bool = ...) -> None: ...
    @overload
    def set(self, array: object, place: CUDAPlace, zero_copy: bool = ...) -> None: ...
    @overload
    def set(self, array: object, place: IPUPlace, zero_copy: bool = ...) -> None: ...
    @overload
    def set(self, array: object, place: CUDAPinnedPlace, zero_copy: bool = ...) -> None: ...
    def set_lod(self, lod: list[list[int]]) -> None: ...
    def set_recursive_sequence_lengths(self, recursive_sequence_lengths: list[list[int]]) -> None: ...
    @overload
    def shape(self) -> list[int]: ...
    @overload
    def shape(self) -> Any: ...
    def __array__(self, dtype: object = ..., copy: object = ...) -> numpy.ndarray: ...
    def __buffer__(self, *args, **kwargs): ...
    def __getitem__(self, arg0: object) -> Tensor: ...
    def __release_buffer__(self, *args, **kwargs): ...

class LoDTensorArray:
    def __init__(self) -> None: ...
    @overload
    def append(self, tensor) -> None: ...
    @overload
    def append(self, t) -> Any: ...
    def __getitem__(self, index): ...
    def __len__(self) -> int: ...
    def __setitem__(self, arg0: int, arg1) -> None: ...

class LoDTensorBlockingQueue:
    def __init__(self, *args, **kwargs) -> None: ...
    def capacity(self) -> int: ...
    def close(self) -> None: ...
    def kill(self) -> None: ...
    def push(self, arg0) -> bool: ...
    def size(self) -> int: ...
    def wait_for_inited(self, arg0: int) -> bool: ...

class LodRankTable:
    def __init__(self, *args, **kwargs) -> None: ...
    def items(self) -> list[tuple[int, int]]: ...

class Machine:
    def __init__(self, *args, **kwargs) -> None: ...
    def contains(self, arg0: int) -> bool: ...
    def device(self, arg0: int) -> Device: ...
    def link(self, arg0: int, arg1: int) -> Link: ...
    @property
    def devices(self) -> dict[int, Device]: ...
    @property
    def id(self) -> int: ...
    @property
    def links(self) -> dict[int, dict[int, Link]]: ...

class MemPythonNode:
    addr: int
    current_allocated: int
    current_reserved: int
    increase_bytes: int
    peak_allocated: int
    peak_reserved: int
    place: str
    process_id: int
    thread_id: int
    timestamp_ns: int
    type: Incomplete
    def __init__(self) -> None: ...

class MultiDeviceFeedReader:
    def __init__(self, *args, **kwargs) -> None: ...
    def read_next(self, *args, **kwargs): ...
    def read_next_list(self, *args, **kwargs): ...
    def read_next_var_list(self, *args, **kwargs): ...
    def reset(self) -> None: ...
    def shutdown(self) -> None: ...

class NativeConfig(PaddlePredictor.Config):
    device: int
    fraction_of_gpu_memory: float
    param_file: str
    prog_file: str
    specify_input_name: bool
    use_gpu: bool
    use_xpu: bool
    def __init__(self) -> None: ...
    def cpu_math_library_num_threads(self) -> int: ...
    def set_cpu_math_library_num_threads(self, arg0: int) -> None: ...

class NativePaddlePredictor(PaddlePredictor):
    def __init__(self, arg0: NativeConfig) -> None: ...
    def clone(self) -> PaddlePredictor: ...
    def get_input_tensor(self, *args, **kwargs): ...
    def get_output_tensor(self, *args, **kwargs): ...
    def init(self, arg0: _Scope) -> bool: ...
    def run(self, arg0: list[PaddleTensor]) -> list[PaddleTensor]: ...
    def scope(self) -> _Scope: ...
    def zero_copy_run(self) -> bool: ...

class Node:
    class Dep:
        __members__: ClassVar[dict] = ...  # read-only
        After: ClassVar[Node.Dep] = ...
        Before: ClassVar[Node.Dep] = ...
        NoDep: ClassVar[Node.Dep] = ...
        Same: ClassVar[Node.Dep] = ...
        __entries: ClassVar[dict] = ...
        def __init__(self, value: int) -> None: ...
        def __eq__(self, other: object) -> bool: ...
        def __hash__(self) -> int: ...
        def __index__(self) -> int: ...
        def __int__(self) -> int: ...
        def __ne__(self, other: object) -> bool: ...
        @property
        def name(self) -> str: ...
        @property
        def value(self) -> int: ...

    class Type:
        __members__: ClassVar[dict] = ...  # read-only
        Operation: ClassVar[Node.Type] = ...
        Variable: ClassVar[Node.Type] = ...
        __entries: ClassVar[dict] = ...
        def __init__(self, value: int) -> None: ...
        def __eq__(self, other: object) -> bool: ...
        def __hash__(self) -> int: ...
        def __index__(self) -> int: ...
        def __int__(self) -> int: ...
        def __ne__(self, other: object) -> bool: ...
        @property
        def name(self) -> str: ...
        @property
        def value(self) -> int: ...
    After: ClassVar[Node.Dep] = ...
    Before: ClassVar[Node.Dep] = ...
    NoDep: ClassVar[Node.Dep] = ...
    Operation: ClassVar[Node.Type] = ...
    Same: ClassVar[Node.Dep] = ...
    Variable: ClassVar[Node.Type] = ...
    inputs: list[Node]
    outputs: list[Node]
    def __init__(self, *args, **kwargs) -> None: ...
    def append_input(self, arg0: Node) -> None: ...
    def append_output(self, arg0: Node) -> None: ...
    def clear_inputs(self) -> None: ...
    def clear_outputs(self) -> None: ...
    def graph_id(self) -> int: ...
    def id(self) -> int: ...
    def is_ctrl_var(self) -> bool: ...
    def is_op(self) -> bool: ...
    def is_var(self) -> bool: ...
    def name(self) -> str: ...
    def node_type(self, *args, **kwargs): ...
    def op(self) -> OpDesc: ...
    def original_desc_id(self) -> int: ...
    @overload
    def remove_input(self, arg0: int) -> None: ...
    @overload
    def remove_input(self, arg0: Node) -> None: ...
    @overload
    def remove_output(self, arg0: int) -> None: ...
    @overload
    def remove_output(self, arg0: Node) -> None: ...
    def var(self) -> VarDesc: ...

class OpAttrInfo(OpUpdateInfo):
    @overload
    def __init__(self, arg0: str, arg1: str, arg2: Variant) -> None: ...
    @overload
    def __init__(self, arg0: OpAttrInfo) -> None: ...
    def default_value(self) -> Variant: ...
    def name(self) -> str: ...
    def remark(self) -> str: ...

class OpBugfixInfo(OpUpdateInfo):
    @overload
    def __init__(self, arg0: str) -> None: ...
    @overload
    def __init__(self, arg0: OpBugfixInfo) -> None: ...
    def remark(self) -> str: ...

class OpCheckpoint:
    def __init__(self, *args, **kwargs) -> None: ...
    def note(self) -> str: ...
    def version_desc(self) -> OpVersionDesc: ...

class OpDesc:
    dist_attr: Incomplete
    def __init__(self) -> None: ...
    def attr(self, name: str, with_attr_var: bool = ...) -> Variant: ...
    def attr_names(self, with_attr_var: bool = ...) -> list[str]: ...
    def attr_type(self, name: str, with_attr_var: bool = ...) -> AttrType: ...
    def block(self) -> BlockDesc: ...
    def check_attrs(self) -> None: ...
    def copy_from(self, arg0: OpDesc) -> None: ...
    def get_attr_map(self) -> dict[str, Variant]: ...
    def has_attr(self, name: str, with_attr_var: bool = ...) -> bool: ...
    def id(self) -> int: ...
    def infer_shape(self, arg0: BlockDesc) -> None: ...
    def infer_var_type(self, arg0: BlockDesc) -> None: ...
    def input(self, arg0: str) -> list[str]: ...
    def input_arg_names(self, with_attr_var: bool = ...) -> list[str]: ...
    def input_names(self, with_attr_var: bool = ...) -> list[str]: ...
    def inputs(self) -> dict[str, list[str]]: ...
    def original_id(self) -> int: ...
    def output(self, arg0: str) -> list[str]: ...
    def output_arg_names(self) -> list[str]: ...
    def output_names(self) -> list[str]: ...
    def outputs(self) -> dict[str, list[str]]: ...
    def remove_attr(self, arg0: str) -> None: ...
    def remove_input(self, arg0: str) -> None: ...
    def remove_output(self, arg0: str) -> None: ...
    def serialize_to_string(self) -> bytes: ...
    def set_block_attr(self, arg0: str, arg1: BlockDesc) -> None: ...
    def set_blocks_attr(self, arg0: str, arg1: list[BlockDesc]) -> None: ...
    def set_input(self, arg0: str, arg1: list[str]) -> None: ...
    def set_is_target(self, arg0: bool) -> None: ...
    def set_original_id(self, arg0: int) -> None: ...
    def set_output(self, arg0: str, arg1: list[str]) -> None: ...
    def set_serialized_attr(self, arg0: str, arg1: bytes) -> None: ...
    def set_type(self, arg0: str) -> None: ...
    def set_var_attr(self, arg0: str, arg1: VarDesc) -> None: ...
    def set_vars_attr(self, arg0: str, arg1: list[VarDesc]) -> None: ...
    def type(self) -> str: ...

class OpInputOutputInfo(OpUpdateInfo):
    @overload
    def __init__(self, arg0: str, arg1: str) -> None: ...
    @overload
    def __init__(self, arg0: OpInputOutputInfo) -> None: ...
    def name(self) -> str: ...
    def remark(self) -> str: ...

class OpUpdateBase:
    def __init__(self, *args, **kwargs) -> None: ...
    def info(self) -> OpUpdateInfo: ...
    def type(self) -> OpUpdateType: ...

class OpUpdateInfo:
    def __init__(self) -> None: ...

class OpUpdateType:
    __members__: ClassVar[dict] = ...  # read-only
    __entries: ClassVar[dict] = ...
    kBugfixWithBehaviorChanged: ClassVar[OpUpdateType] = ...
    kInvalid: ClassVar[OpUpdateType] = ...
    kModifyAttr: ClassVar[OpUpdateType] = ...
    kNewAttr: ClassVar[OpUpdateType] = ...
    kNewInput: ClassVar[OpUpdateType] = ...
    kNewOutput: ClassVar[OpUpdateType] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class OpVersion:
    def __init__(self, *args, **kwargs) -> None: ...
    def checkpoints(self) -> list[OpCheckpoint]: ...
    def version_id(self) -> int: ...

class OpVersionDesc:
    def __init__(self, *args, **kwargs) -> None: ...
    def infos(self) -> list: ...

class Operator:
    def __init__(self, *args, **kwargs) -> None: ...
    @staticmethod
    def create(arg0: bytes) -> Operator: ...
    def input_vars(self) -> list[str]: ...
    def inputs(self) -> dict[str, list[str]]: ...
    def no_intermediate_outputs(self) -> list[str]: ...
    def output_vars(self) -> list[str]: ...
    def outputs(self) -> dict[str, list[str]]: ...
    @overload
    def run(self, arg0: _Scope, arg1) -> None: ...
    @overload
    def run(self, arg0: _Scope, arg1) -> None: ...
    @overload
    def run(self, arg0: _Scope, arg1) -> None: ...
    @overload
    def run(self, arg0: _Scope, arg1) -> None: ...
    @overload
    def run(self, arg0: _Scope, arg1) -> None: ...
    def support_gpu(self) -> bool: ...
    def type(self) -> str: ...

class OperatorDistAttr:
    annotated: dict[str, bool]
    chunk_id: int
    event_to_record: str
    events_to_wait: list[str]
    execution_stream: str
    force_record_event: bool
    impl_idx: int
    impl_type: str
    inputs_dist_attrs: dict[str, TensorDistAttr]
    is_recompute: bool
    op_type: str
    outputs_dist_attrs: dict[str, TensorDistAttr]
    process_mesh: ProcessMesh
    run_time_us: float
    scheduling_priority: int
    stream_priority: int
    @overload
    def __init__(self) -> None: ...
    @overload
    def __init__(self, arg0: OpDesc) -> None: ...
    @overload
    def __init__(self, arg0: OperatorDistAttr) -> None: ...
    def clear_annotated(self) -> None: ...
    def del_input_dist_attr(self, arg0: str) -> None: ...
    def del_output_dist_attr(self, arg0: str) -> None: ...
    def get_input_dims_mapping(self, arg0: str) -> list[int]: ...
    def get_input_dist_attr(self, arg0: str) -> TensorDistAttr: ...
    def get_output_dims_mapping(self, arg0: str) -> list[int]: ...
    def get_output_dist_attr(self, arg0: str) -> TensorDistAttr: ...
    def is_annotated(self, arg0: str) -> bool: ...
    def is_annotated_input_dims_mapping(self, arg0: str) -> bool: ...
    def is_annotated_output_dims_mapping(self, arg0: str) -> bool: ...
    def mark_annotated(self, arg0: str) -> None: ...
    def parse_from_string(self, arg0: str) -> None: ...
    def rename_input(self, arg0: str, arg1: str) -> None: ...
    def rename_output(self, arg0: str, arg1: str) -> None: ...
    def reset(self) -> None: ...
    def serialize_to_string(self) -> bytes: ...
    def set_input_dims_mapping(self, arg0: str, arg1: list[int]) -> None: ...
    def set_input_dist_attr(self, arg0: str, arg1: TensorDistAttr) -> None: ...
    def set_output_dims_mapping(self, arg0: str, arg1: list[int]) -> None: ...
    def set_output_dist_attr(self, arg0: str, arg1: TensorDistAttr) -> None: ...
    def verify(self, op: OpDesc = ...) -> bool: ...
    def __copy__(self) -> OperatorDistAttr: ...
    def __deepcopy__(self, memo: dict) -> OperatorDistAttr: ...
    def __eq__(self, arg0: OperatorDistAttr) -> bool: ...
    def __ne__(self, arg0: OperatorDistAttr) -> bool: ...

class OrderedMultiDeviceFeedReader:
    def __init__(self, *args, **kwargs) -> None: ...
    def read_next(self, *args, **kwargs): ...
    def read_next_list(self, *args, **kwargs): ...
    def read_next_var_list(self, *args, **kwargs): ...
    def reset(self) -> None: ...
    def shutdown(self) -> None: ...

class OrderedMultiDeviceLoDTensorBlockingQueue:
    def __init__(self, *args, **kwargs) -> None: ...
    def capacity(self) -> int: ...
    def close(self) -> None: ...
    def kill(self) -> None: ...
    def push(self, arg0) -> bool: ...
    def reset(self) -> None: ...
    def size(self) -> int: ...
    def wait_for_inited(self, arg0: int) -> bool: ...

class P2POption:
    def __init__(self) -> None: ...

class PToRReshardFunction(ReshardFunction):
    def __init__(self) -> None: ...

class PToRReshardFunctionCrossMesh(ReshardFunction):
    def __init__(self) -> None: ...

class PToSReshardFunction(ReshardFunction):
    def __init__(self) -> None: ...

class PaddleBuf:
    @overload
    def __init__(self, arg0: int) -> None: ...
    @overload
    def __init__(self, arg0: list[float]) -> None: ...
    @overload
    def __init__(self, arg0: numpy.ndarray[numpy.int32]) -> None: ...
    @overload
    def __init__(self, arg0: numpy.ndarray[numpy.int64]) -> None: ...
    @overload
    def __init__(self, arg0: numpy.ndarray[numpy.float32]) -> None: ...
    def empty(self) -> bool: ...
    def float_data(self) -> list[float]: ...
    def int32_data(self) -> list[int]: ...
    def int64_data(self) -> list[int]: ...
    def length(self) -> int: ...
    @overload
    def reset(self, arg0: list[float]) -> None: ...
    @overload
    def reset(self, arg0: numpy.ndarray[numpy.int32]) -> None: ...
    @overload
    def reset(self, arg0: numpy.ndarray[numpy.int64]) -> None: ...
    @overload
    def reset(self, arg0: numpy.ndarray[numpy.float32]) -> None: ...
    def resize(self, arg0: int) -> None: ...
    def tolist(self, arg0: str) -> list: ...

class PaddleDType:
    __members__: ClassVar[dict] = ...  # read-only
    BOOL: ClassVar[PaddleDType] = ...
    FLOAT16: ClassVar[PaddleDType] = ...
    FLOAT32: ClassVar[PaddleDType] = ...
    FLOAT64: ClassVar[PaddleDType] = ...
    INT32: ClassVar[PaddleDType] = ...
    INT64: ClassVar[PaddleDType] = ...
    INT8: ClassVar[PaddleDType] = ...
    UINT8: ClassVar[PaddleDType] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class PaddleDataLayout:
    __members__: ClassVar[dict] = ...  # read-only
    Any: ClassVar[PaddleDataLayout] = ...
    NCHW: ClassVar[PaddleDataLayout] = ...
    NHWC: ClassVar[PaddleDataLayout] = ...
    UNK: ClassVar[PaddleDataLayout] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class PaddleInferPredictor:
    def __init__(self, arg0: AnalysisConfig) -> None: ...
    def clear_intermediate_tensor(self) -> None: ...
    def clone(self) -> PaddleInferPredictor: ...
    def get_input_handle(self, *args, **kwargs): ...
    def get_input_names(self) -> list[str]: ...
    def get_output_handle(self, *args, **kwargs): ...
    def get_output_names(self) -> list[str]: ...
    def register_output_hook(self, arg0) -> None: ...
    @overload
    def run(self, inputs: object) -> object: ...
    @overload
    def run(self) -> None: ...
    def try_shrink_memory(self) -> int: ...

class PaddleInferTensor:
    copy_from_cpu: ClassVar[Callable] = ...
    share_external_data: ClassVar[Callable] = ...
    def __init__(self, *args, **kwargs) -> None: ...
    def copy_to_cpu(self) -> numpy.ndarray: ...
    def lod(self) -> list[list[int]]: ...
    @overload
    def reshape(self, arg0: list[int]) -> None: ...
    @overload
    def reshape(self, arg0: int) -> None: ...
    def set_lod(self, arg0: list[list[int]]) -> None: ...
    def shape(self) -> list[int]: ...
    def type(self) -> PaddleDType: ...

class PaddlePassBuilder:
    def __init__(self, arg0: list[str]) -> None: ...
    def all_passes(self) -> list[str]: ...
    def analysis_passes(self) -> list[str]: ...
    def append_analysis_pass(self, arg0: str) -> None: ...
    def append_pass(self, arg0: str) -> None: ...
    def debug_string(self) -> str: ...
    def delete_pass(self, arg0: str) -> None: ...
    def insert_pass(self, arg0: int, arg1: str) -> None: ...
    def set_passes(self, arg0: list[str]) -> None: ...
    def turn_on_debug(self) -> None: ...

class PaddlePlace:
    __members__: ClassVar[dict] = ...  # read-only
    CPU: ClassVar[PaddlePlace] = ...
    CUSTOM: ClassVar[PaddlePlace] = ...
    GPU: ClassVar[PaddlePlace] = ...
    UNK: ClassVar[PaddlePlace] = ...
    XPU: ClassVar[PaddlePlace] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class PaddlePredictor:
    class Config:
        model_dir: str
        def __init__(self) -> None: ...
    def __init__(self, *args, **kwargs) -> None: ...
    def clone(self) -> PaddlePredictor: ...
    def get_input_names(self) -> list[str]: ...
    def get_input_tensor(self, *args, **kwargs): ...
    def get_output_names(self) -> list[str]: ...
    def get_output_tensor(self, *args, **kwargs): ...
    def get_serialized_program(self) -> str: ...
    def run(self, arg0: list[PaddleTensor]) -> list[PaddleTensor]: ...
    def zero_copy_run(self) -> bool: ...

class PaddleTensor:
    data: PaddleBuf
    dtype: PaddleDType
    lod: list[list[int]]
    name: str
    shape: list[int]
    @overload
    def __init__(self) -> None: ...
    @overload
    def __init__(self, data: numpy.ndarray[numpy.int32], name: str = ..., lod: list[list[int]] = ..., copy: bool = ...) -> None: ...
    @overload
    def __init__(self, data: numpy.ndarray[numpy.int64], name: str = ..., lod: list[list[int]] = ..., copy: bool = ...) -> None: ...
    @overload
    def __init__(self, data: numpy.ndarray[numpy.float32], name: str = ..., lod: list[list[int]] = ..., copy: bool = ...) -> None: ...
    def as_ndarray(self) -> numpy.ndarray: ...

class ParallelExecutor:
    class BuildStrategy:
        class GradientScaleStrategy:
            __members__: ClassVar[dict] = ...  # read-only
            CoeffNumDevice: ClassVar[ParallelExecutor.BuildStrategy.GradientScaleStrategy] = ...
            Customized: ClassVar[ParallelExecutor.BuildStrategy.GradientScaleStrategy] = ...
            One: ClassVar[ParallelExecutor.BuildStrategy.GradientScaleStrategy] = ...
            __entries: ClassVar[dict] = ...
            def __init__(self, value: int) -> None: ...
            def __eq__(self, other: object) -> bool: ...
            def __hash__(self) -> int: ...
            def __index__(self) -> int: ...
            def __int__(self) -> int: ...
            def __ne__(self, other: object) -> bool: ...
            @property
            def name(self) -> str: ...
            @property
            def value(self) -> int: ...

        class ReduceStrategy:
            __members__: ClassVar[dict] = ...  # read-only
            AllReduce: ClassVar[ParallelExecutor.BuildStrategy.ReduceStrategy] = ...
            Reduce: ClassVar[ParallelExecutor.BuildStrategy.ReduceStrategy] = ...
            _NoReduce: ClassVar[ParallelExecutor.BuildStrategy.ReduceStrategy] = ...
            __entries: ClassVar[dict] = ...
            def __init__(self, value: int) -> None: ...
            def __eq__(self, other: object) -> bool: ...
            def __hash__(self) -> int: ...
            def __index__(self) -> int: ...
            def __int__(self) -> int: ...
            def __ne__(self, other: object) -> bool: ...
            @property
            def name(self) -> str: ...
            @property
            def value(self) -> int: ...
        allow_cuda_graph_capture: bool
        async_mode: bool
        bkcl_comm_num: int
        build_cinn_pass: bool
        cache_runtime_context: bool
        debug_graphviz_path: str
        enable_addto: bool
        enable_auto_fusion: bool
        enable_backward_optimizer_op_deps: bool
        enable_inplace: bool
        enable_sequential_execution: bool
        fix_op_run_order: bool
        fuse_adamw: bool
        fuse_all_optimizer_ops: bool
        fuse_all_reduce_ops: bool
        fuse_bn_act_ops: bool
        fuse_bn_add_act_ops: bool
        fuse_broadcast_ops: bool
        fuse_elewise_add_act_ops: bool
        fuse_gemm_epilogue: bool
        fuse_relu_depthwise_conv: bool
        fused_attention: bool
        fused_feedforward: bool
        gradient_scale_strategy: Incomplete
        hierarchical_allreduce_inter_nranks: int
        is_distribution: bool
        memory_optimize: object
        mkldnn_enabled_op_types: set[str]
        nccl_comm_num: int
        num_trainers: int
        reduce_strategy: Incomplete
        remove_unnecessary_lock: bool
        sequential_run: bool
        sync_batch_norm: bool
        trainer_id: int
        trainers_endpoints: list[str]
        use_hierarchical_allreduce: bool
        def __init__(self) -> None: ...

    class ExecutionStrategy:
        allow_op_delay: bool
        num_iteration_per_drop_scope: int
        num_iteration_per_run: int
        num_threads: int
        use_experimental_executor: bool
        use_thread_barrier: bool
        def __init__(self) -> None: ...
    def __init__(self, arg0, arg1: list[str], arg2: str, arg3: _Scope, arg4: list[_Scope], arg5: ParallelExecutor.ExecutionStrategy, arg6: ParallelExecutor.BuildStrategy, arg7) -> None: ...
    def device_count(self) -> int: ...
    def drop_local_exe_scopes(self) -> None: ...
    def feed_and_split_tensor_into_local_scopes(self, arg0) -> None: ...
    def feed_tensors_into_local_scopes(self, arg0) -> None: ...
    def local_scopes(self) -> list[_Scope]: ...
    def run(self, arg0: list[str], arg1: bool) -> object: ...

class ParallelStrategy:
    current_endpoint: str
    local_rank: int
    nranks: int
    nrings: int
    trainer_endpoints: list[str]
    def __init__(self) -> None: ...

class Partial(Placement):
    def __init__(self, reduce_type: ReduceType = ...) -> None: ...
    def __eq__(self, arg0: Partial) -> bool: ...
    def __hash__(self) -> int: ...
    def __ne__(self, arg0: Partial) -> bool: ...

class Pass:
    def __init__(self) -> None: ...
    def apply(self, arg0) -> None: ...
    def has(self, arg0: str) -> bool: ...
    @overload
    def set(self, arg0: str, arg1: str) -> None: ...
    @overload
    def set(self, arg0: str, arg1: bool) -> None: ...
    @overload
    def set(self, arg0: str, arg1: int) -> None: ...
    @overload
    def set(self, arg0: str, arg1: list[str]) -> None: ...
    @overload
    def set(self, arg0: str, arg1: set[str]) -> None: ...
    @overload
    def set(self, arg0: str, arg1: set[int]) -> None: ...
    @overload
    def set(self, arg0: str, arg1) -> None: ...
    def set_not_owned(self, arg0: str, arg1: ProgramDesc) -> None: ...
    def type(self) -> str: ...

class PassBuilder:
    def __init__(self) -> None: ...
    def all_passes(self) -> list[Pass]: ...
    def append_pass(self, arg0: str) -> Pass: ...
    def insert_pass(self, arg0: int, arg1: str) -> Pass: ...
    def remove_pass(self, arg0: int) -> None: ...

class PassStrategy(PaddlePassBuilder):
    def __init__(self, arg0: list[str]) -> None: ...
    def enable_cudnn(self) -> None: ...
    def enable_mkldnn(self) -> None: ...
    def enable_mkldnn_bfloat16(self) -> None: ...
    def enable_mkldnn_quantizer(self) -> None: ...
    def use_gpu(self) -> bool: ...

class PassVersionChecker:
    def __init__(self, *args, **kwargs) -> None: ...
    @staticmethod
    def IsCompatible(arg0: str) -> bool: ...

class Place:
    def __init__(self) -> None: ...
    def custom_device_id(self) -> int: ...
    def custom_device_type(self) -> str: ...
    def gpu_device_id(self) -> int: ...
    def ipu_device_id(self) -> int: ...
    def is_cpu_place(self) -> bool: ...
    def is_cuda_pinned_place(self) -> bool: ...
    def is_custom_place(self) -> bool: ...
    def is_gpu_place(self) -> bool: ...
    def is_ipu_place(self) -> bool: ...
    def is_xpu_place(self) -> bool: ...
    @overload
    def set_place(self, arg0: Place) -> None: ...
    @overload
    def set_place(self, arg0: CPUPlace) -> None: ...
    @overload
    def set_place(self, arg0: XPUPlace) -> None: ...
    @overload
    def set_place(self, arg0: CUDAPlace) -> None: ...
    @overload
    def set_place(self, arg0: CUDAPinnedPlace) -> None: ...
    @overload
    def set_place(self, arg0: IPUPlace) -> None: ...
    @overload
    def set_place(self, arg0: CustomPlace) -> None: ...
    def xpu_device_id(self) -> int: ...

class Placement:
    def __init__(self) -> None: ...
    def is_partial(self) -> bool: ...
    def is_replicated(self) -> bool: ...
    def is_shard(self, dim: int | None = ...) -> bool: ...
    def __eq__(self, arg0: Placement) -> bool: ...
    def __hash__(self) -> int: ...
    def __ne__(self, arg0: Placement) -> bool: ...

class Plan:
    @overload
    def __init__(self, job_list: list[Job], type_to_program) -> None: ...
    @overload
    def __init__(self, job_list: list[Job], type_to_ir_program) -> None: ...
    def ir_program(self, *args, **kwargs): ...
    def job_list(self) -> list[Job]: ...
    def job_types(self) -> list[str]: ...
    def micro_batch_num(self) -> int: ...
    def program(self, *args, **kwargs): ...
    def set_ir_program(self, arg0: str, arg1) -> None: ...

class PredictorPool:
    def __init__(self, arg0: AnalysisConfig, arg1: int) -> None: ...
    def retrive(self, arg0: int) -> PaddleInferPredictor: ...

class ProcessGroup:
    def __init__(self, *args, **kwargs) -> None: ...
    def all_gather(self, *args, **kwargs): ...
    def all_gather_into_tensor(self, *args, **kwargs): ...
    def all_gather_into_tensor_on_calc_stream(self, *args, **kwargs): ...
    def all_gather_on_calc_stream(self, *args, **kwargs): ...
    def all_gather_partial(self, *args, **kwargs): ...
    def all_gather_partial_on_calc_stream(self, *args, **kwargs): ...
    def all_reduce(self, *args, **kwargs): ...
    def all_reduce_on_calc_stream(self, *args, **kwargs): ...
    def all_to_all(self, *args, **kwargs): ...
    def all_to_all_on_calc_stream(self, *args, **kwargs): ...
    def all_to_all_single(self, *args, **kwargs): ...
    def all_to_all_single_on_calc_stream(self, *args, **kwargs): ...
    def all_to_all_tensor(self, *args, **kwargs): ...
    def all_to_all_tensor_on_calc_stream(self, *args, **kwargs): ...
    def allreduce(self, *args, **kwargs): ...
    def alltoall(self, *args, **kwargs): ...
    def alltoall_single(self, *args, **kwargs): ...
    def barrier(self, *args, **kwargs): ...
    def broadcast(self, *args, **kwargs): ...
    def broadcast_on_calc_stream(self, *args, **kwargs): ...
    def gather(self, *args, **kwargs): ...
    def name(self) -> str: ...
    def rank(self) -> int: ...
    def recv(self, *args, **kwargs): ...
    def recv_on_calc_stream(self, *args, **kwargs): ...
    def recv_partial(self, *args, **kwargs): ...
    def recv_partial_on_calc_stream(self, *args, **kwargs): ...
    def reduce(self, *args, **kwargs): ...
    def reduce_on_calc_stream(self, *args, **kwargs): ...
    def reduce_scatter(self, *args, **kwargs): ...
    def reduce_scatter_on_calc_stream(self, *args, **kwargs): ...
    def reduce_scatter_tensor(self, *args, **kwargs): ...
    def reduce_scatter_tensor_on_calc_stream(self, *args, **kwargs): ...
    def scatter(self, *args, **kwargs): ...
    def scatter_on_calc_stream(self, *args, **kwargs): ...
    def scatter_tensor(self, *args, **kwargs): ...
    def scatter_tensor_on_calc_stream(self, *args, **kwargs): ...
    def send(self, *args, **kwargs): ...
    def send_on_calc_stream(self, *args, **kwargs): ...
    def send_partial(self, *args, **kwargs): ...
    def send_partial_on_calc_stream(self, *args, **kwargs): ...
    def size(self) -> int: ...

class ProcessGroupIdMap:
    def __init__(self, *args, **kwargs) -> None: ...
    @staticmethod
    def destroy() -> None: ...

class ProcessMesh:
    @overload
    def __init__(self) -> None: ...
    @overload
    def __init__(self, shape: list[int], process_ids: list[int], dim_names: list[str]) -> None: ...
    def contains(self, arg0: int) -> bool: ...
    @overload
    def dim_size(self, arg0: int) -> int: ...
    @overload
    def dim_size(self, arg0: str) -> int: ...
    def empty(self) -> bool: ...
    def __copy__(self) -> ProcessMesh: ...
    def __deepcopy__(self, memo: dict) -> ProcessMesh: ...
    def __eq__(self, arg0: ProcessMesh) -> bool: ...
    def __ne__(self, arg0: ProcessMesh) -> bool: ...
    @property
    def dim_names(self) -> list[str]: ...
    @property
    def ndim(self) -> int: ...
    @property
    def process_ids(self) -> list[int]: ...
    @property
    def shape(self) -> list[int]: ...
    @property
    def size(self) -> int: ...

class ProfilerOptions:
    trace_switch: int
    def __init__(self) -> None: ...

class ProfilerState:
    __members__: ClassVar[dict] = ...  # read-only
    __entries: ClassVar[dict] = ...
    kAll: ClassVar[ProfilerState] = ...
    kCPU: ClassVar[ProfilerState] = ...
    kCUDA: ClassVar[ProfilerState] = ...
    kDisabled: ClassVar[ProfilerState] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __ge__(self, other: object) -> bool: ...
    def __gt__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __le__(self, other: object) -> bool: ...
    def __lt__(self, other: object) -> bool: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class ProgramDesc:
    @overload
    def __init__(self) -> None: ...
    @overload
    def __init__(self, arg0: ProgramDesc) -> None: ...
    @overload
    def __init__(self, arg0: bytes) -> None: ...
    def append_block(self, *args, **kwargs): ...
    def block(self, *args, **kwargs): ...
    def cached_hash_str(self) -> str: ...
    def flush(self) -> None: ...
    def get_feed_target_names(self) -> list[str]: ...
    def get_fetch_target_names(self) -> list[str]: ...
    def get_op_deps(self, *args, **kwargs): ...
    @overload
    def need_update(self) -> bool: ...
    @overload
    def need_update(self) -> bool: ...
    def num_blocks(self) -> int: ...
    def parse_from_string(self, arg0: str) -> None: ...
    def serialize_to_string(self, legacy_format: bool = ...) -> bytes: ...

class ProgramDescTracer:
    def __init__(self, *args, **kwargs) -> None: ...
    def create_program_desc(self, *args, **kwargs): ...
    def reset(self) -> None: ...

class Property:
    def __init__(self) -> None: ...
    @overload
    def get_float(self, arg0: int) -> float: ...
    @overload
    def get_float(self, arg0: str) -> float: ...
    def parse_from_string(self, arg0: str) -> None: ...
    def serialize_to_string(self) -> bytes: ...
    def set_float(self, name: str, var: float) -> None: ...
    def set_floats(self, name: str, val: list[float]) -> None: ...
    def set_int(self, name: str, val: int) -> None: ...
    def set_ints(self, name: str, val: list[int]) -> None: ...
    def set_string(self, name: str, val: str) -> None: ...
    def set_strings(self, name: str, val: list[str]) -> None: ...
    def size(self) -> int: ...

class RToPReshardFunction(ReshardFunction):
    def __init__(self) -> None: ...

class RToPReshardFunctionCrossMesh(ReshardFunction):
    def __init__(self) -> None: ...

class RToSReshardFunction(ReshardFunction):
    def __init__(self) -> None: ...

class RToSReshardFunctionCrossMesh(ReshardFunction):
    def __init__(self) -> None: ...

class Reader:
    def __init__(self, *args, **kwargs) -> None: ...
    def reset(self) -> None: ...
    def start(self) -> None: ...

class ReduceOp:
    __members__: ClassVar[dict] = ...  # read-only
    AVG: ClassVar[ReduceOp] = ...
    MAX: ClassVar[ReduceOp] = ...
    MIN: ClassVar[ReduceOp] = ...
    PRODUCT: ClassVar[ReduceOp] = ...
    SUM: ClassVar[ReduceOp] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class ReduceOptions:
    reduce_op: ReduceOp
    source_root: int
    def __init__(self) -> None: ...

class ReduceType:
    __members__: ClassVar[dict] = ...  # read-only
    __entries: ClassVar[dict] = ...
    kRedAll: ClassVar[ReduceType] = ...
    kRedAny: ClassVar[ReduceType] = ...
    kRedAvg: ClassVar[ReduceType] = ...
    kRedMax: ClassVar[ReduceType] = ...
    kRedMin: ClassVar[ReduceType] = ...
    kRedProd: ClassVar[ReduceType] = ...
    kRedSum: ClassVar[ReduceType] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class Replicate(Placement):
    def __init__(self) -> None: ...
    def __eq__(self, arg0: Replicate) -> bool: ...
    def __hash__(self) -> int: ...
    def __ne__(self, arg0: Replicate) -> bool: ...

class ReshardFunction:
    def __init__(self, *args, **kwargs) -> None: ...
    def eval(self, *args, **kwargs): ...
    def is_suitable(self, arg0: object, arg1) -> bool: ...

class SPMDRuleBase:
    def __init__(self, *args, **kwargs) -> None: ...
    def infer_backward(self, arg0, arg1, arg2: dict[str, Variant]) -> tuple[list[TensorDistAttr], list[TensorDistAttr]]: ...
    def infer_forward(self, arg0, arg1: dict[str, Variant]) -> tuple[list[TensorDistAttr], list[TensorDistAttr]]: ...

class SToPReshardFunction(ReshardFunction):
    def __init__(self) -> None: ...

class SToRReshardFunction(ReshardFunction):
    def __init__(self) -> None: ...

class SToRReshardFunctionCrossMesh(ReshardFunction):
    def __init__(self) -> None: ...

class SToSReshardFunction(ReshardFunction):
    def __init__(self) -> None: ...

class SameNdMeshReshardFunction(ReshardFunction):
    def __init__(self) -> None: ...

class SameStatusReshardFunction(ReshardFunction):
    def __init__(self) -> None: ...

class Scalar:
    @overload
    def __init__(self, arg0: bool) -> None: ...
    @overload
    def __init__(self, arg0: float) -> None: ...
    @overload
    def __init__(self, arg0: int) -> None: ...
    @overload
    def __init__(self, arg0: complex) -> None: ...
    @overload
    def __init__(self, arg0: Scalar) -> None: ...
    def value(self) -> Variant: ...
    def __eq__(self, arg0: Scalar) -> bool: ...

class SelectedRows:
    @overload
    def __init__(self) -> None: ...
    @overload
    def __init__(self, arg0: list[int], arg1: int) -> None: ...
    def get_tensor(self) -> Tensor: ...
    def height(self) -> int: ...
    def numel(self) -> int: ...
    def rows(self) -> list[int]: ...
    def set_height(self, arg0: int) -> None: ...
    def set_rows(self, arg0: list[int]) -> None: ...
    def sync_index(self) -> None: ...

class Shard(Placement):
    def __init__(self, arg0: int) -> None: ...
    def get_dim(self) -> int: ...
    def __eq__(self, arg0: Shard) -> bool: ...
    def __hash__(self) -> int: ...
    def __ne__(self, arg0: Shard) -> bool: ...

class SparseCooTensor:
    def __init__(self) -> None: ...
    def indices(self) -> Tensor: ...
    def numel(self) -> int: ...

class SpmdRule:
    def __init__(self, *args, **kwargs) -> None: ...
    def infer_backward(self, *args) -> tuple[list[Variant], list[Variant]]: ...
    def infer_forward(self, *args) -> tuple[list[Variant], list[Variant]]: ...

class StandaloneExecutor:
    def __init__(self, arg0, arg1, arg2: _Scope) -> None: ...
    def run(self, arg0: list[str], arg1: bool) -> object: ...
    def run_profile(self, arg0: list[str]) -> object: ...

class Store:
    def __init__(self) -> None: ...
    def add(self, arg0: str, arg1: int) -> int: ...
    def get(self, key: str) -> bytes: ...
    def set(self, key: str, value: str) -> None: ...
    def wait(self, arg0: str) -> None: ...

class TCPStore(Store):
    def __init__(self, hostname: str, port: int, is_master: bool, world_size: int, timeout: int = ...) -> None: ...

class TaskNode:
    @overload
    def __init__(self, arg0: ProgramDesc, arg1: int, arg2: int, arg3: int) -> None: ...
    @overload
    def __init__(self, arg0: int, arg1: list[OpDesc], arg2: int, arg3: int, arg4: int) -> None: ...
    def add_downstream_task(self, arg0: int, arg1: int, arg2: DependType) -> bool: ...
    def add_upstream_task(self, arg0: int, arg1: int, arg2: DependType) -> bool: ...
    def init(self) -> None: ...
    def role(self) -> int: ...
    def set_cond_var_name(self, arg0: str) -> None: ...
    def set_program(self, arg0: ProgramDesc) -> None: ...
    def set_run_at_offset(self, arg0: int) -> None: ...
    def set_run_pre_steps(self, arg0: int) -> None: ...
    def set_type(self, arg0: str) -> None: ...
    def set_vars_to_dtype(self, arg0: dict[str, str]) -> None: ...
    def set_vars_to_shape(self, arg0: dict[str, list[int]]) -> None: ...
    def task_id(self) -> int: ...

class Tensor:
    @overload
    def __init__(self, arg0: list[list[int]]) -> None: ...
    @overload
    def __init__(self) -> None: ...
    @overload
    def has_valid_recursive_sequence_lengths(self) -> bool: ...
    @overload
    def has_valid_recursive_sequence_lengths(self) -> Any: ...
    @overload
    def lod(self) -> list[list[int]]: ...
    @overload
    def lod(self) -> Any: ...
    @overload
    def recursive_sequence_lengths(self) -> list[list[int]]: ...
    @overload
    def recursive_sequence_lengths(self) -> Any: ...
    @overload
    def set(self, array: object, place: CPUPlace, zero_copy: bool = ...) -> None: ...
    @overload
    def set(self, array: object, place: CustomPlace, zero_copy: bool = ...) -> None: ...
    @overload
    def set(self, array: object, place: XPUPlace, zero_copy: bool = ...) -> None: ...
    @overload
    def set(self, array: object, place: CUDAPlace, zero_copy: bool = ...) -> None: ...
    @overload
    def set(self, array: object, place: IPUPlace, zero_copy: bool = ...) -> None: ...
    @overload
    def set(self, array: object, place: CUDAPinnedPlace, zero_copy: bool = ...) -> None: ...
    def set_lod(self, lod: list[list[int]]) -> None: ...
    def set_recursive_sequence_lengths(self, recursive_sequence_lengths: list[list[int]]) -> None: ...
    @overload
    def shape(self) -> list[int]: ...
    @overload
    def shape(self) -> Any: ...
    def __array__(self, dtype: object = ..., copy: object = ...) -> numpy.ndarray: ...
    def __buffer__(self, *args, **kwargs): ...
    def __getitem__(self, arg0: object) -> Tensor: ...
    def __release_buffer__(self, *args, **kwargs): ...

class TensorDistAttr:
    annotated: dict[str, bool]
    batch_dim: int
    chunk_id: int
    dims_mapping: list[int]
    dynamic_dims: list[bool]
    process_mesh: ProcessMesh
    @overload
    def __init__(self) -> None: ...
    @overload
    def __init__(self, arg0: VarDesc) -> None: ...
    @overload
    def __init__(self, arg0: TensorDistAttr) -> None: ...
    def clear_annotated(self) -> None: ...
    def is_annotated(self, arg0: str) -> bool: ...
    def mark_annotated(self, arg0: str) -> None: ...
    def parse_from_string(self, arg0: str) -> None: ...
    def reset(self) -> None: ...
    def serialize_to_string(self) -> bytes: ...
    def verify(self, tensor: VarDesc = ...) -> bool: ...
    def __copy__(self) -> TensorDistAttr: ...
    def __deepcopy__(self, memo: dict) -> TensorDistAttr: ...
    def __eq__(self, arg0: TensorDistAttr) -> bool: ...
    def __ne__(self, arg0: TensorDistAttr) -> bool: ...

class Tracer:
    def __init__(self) -> None: ...

class TracerEventType:
    __members__: ClassVar[dict] = ...  # read-only
    Backward: ClassVar[TracerEventType] = ...
    Communication: ClassVar[TracerEventType] = ...
    CudaRuntime: ClassVar[TracerEventType] = ...
    Dataloader: ClassVar[TracerEventType] = ...
    Forward: ClassVar[TracerEventType] = ...
    Kernel: ClassVar[TracerEventType] = ...
    Memcpy: ClassVar[TracerEventType] = ...
    Memset: ClassVar[TracerEventType] = ...
    Operator: ClassVar[TracerEventType] = ...
    OperatorInner: ClassVar[TracerEventType] = ...
    Optimization: ClassVar[TracerEventType] = ...
    ProfileStep: ClassVar[TracerEventType] = ...
    PythonOp: ClassVar[TracerEventType] = ...
    PythonUserDefined: ClassVar[TracerEventType] = ...
    UserDefined: ClassVar[TracerEventType] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class TracerMemEventType:
    __members__: ClassVar[dict] = ...  # read-only
    Allocate: ClassVar[TracerMemEventType] = ...
    Free: ClassVar[TracerMemEventType] = ...
    ReservedAllocate: ClassVar[TracerMemEventType] = ...
    ReservedFree: ClassVar[TracerMemEventType] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class TracerOption:
    __members__: ClassVar[dict] = ...  # read-only
    __entries: ClassVar[dict] = ...
    kAllOpDetail: ClassVar[TracerOption] = ...
    kDefault: ClassVar[TracerOption] = ...
    kOpDetail: ClassVar[TracerOption] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __ge__(self, other: object) -> bool: ...
    def __gt__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __le__(self, other: object) -> bool: ...
    def __lt__(self, other: object) -> bool: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class TrainerBase:
    def __init__(self, *args, **kwargs) -> None: ...
    def ResetDataset(self, arg0) -> None: ...
    def finalize(self) -> None: ...
    def get_worker_scope(self, arg0: int) -> _Scope: ...

class VarDesc:
    VarType: ClassVar[type[paddle.dtype]] = ...
    dist_attr: Incomplete
    def __init__(self, arg0: str) -> None: ...
    def attr(self, arg0: str) -> Variant: ...
    def attr_names(self) -> list[str]: ...
    def clear_is_parameter(self) -> None: ...
    def clear_stop_gradient(self) -> None: ...
    def dtype(self, *args, **kwargs): ...
    def dtypes(self, *args, **kwargs): ...
    def element_size(self) -> int: ...
    def get_shape(self) -> list[int]: ...
    def has_attr(self, arg0: str) -> bool: ...
    def has_is_parameter(self) -> bool: ...
    def has_stop_gradient(self) -> bool: ...
    def id(self) -> int: ...
    def is_parameter(self) -> bool: ...
    def lod_level(self) -> int: ...
    def lod_levels(self) -> list[int]: ...
    def name(self) -> str: ...
    def need_check_feed(self) -> bool: ...
    def original_id(self) -> int: ...
    def persistable(self) -> bool: ...
    def remove_attr(self, arg0: str) -> None: ...
    def serialize_to_string(self) -> bytes: ...
    def set_dtype(self, arg0) -> None: ...
    def set_dtypes(self, arg0) -> None: ...
    def set_is_parameter(self, arg0: bool) -> None: ...
    def set_lod_level(self, arg0: int) -> None: ...
    def set_lod_levels(self, arg0: list[int]) -> None: ...
    def set_name(self, arg0: str) -> None: ...
    def set_need_check_feed(self, arg0: bool) -> None: ...
    def set_original_id(self, arg0: int) -> None: ...
    def set_persistable(self, arg0: bool) -> None: ...
    def set_shape(self, arg0: list[int]) -> None: ...
    def set_shapes(self, arg0: list[list[int]]) -> None: ...
    def set_stop_gradient(self, arg0: bool) -> None: ...
    def set_type(self, arg0) -> None: ...
    def shape(self) -> list[int]: ...
    def shapes(self) -> list[list[int]]: ...
    def stop_gradient(self) -> bool: ...
    def type(self, *args, **kwargs): ...

class Variable:
    def __init__(self) -> None: ...
    def get_bytes(self) -> bytes: ...
    def get_fetch_list(self, *args, **kwargs): ...
    def get_float(self) -> float: ...
    def get_int(self) -> int: ...
    def get_lod_rank_table(self, *args, **kwargs): ...
    def get_lod_tensor_array(self, *args, **kwargs): ...
    def get_map_tensor(self, *args, **kwargs): ...
    def get_reader(self, *args, **kwargs): ...
    def get_scope(self, *args, **kwargs): ...
    def get_selected_rows(self, *args, **kwargs): ...
    def get_string_tensor(self, *args, **kwargs): ...
    def get_tensor(self, *args, **kwargs): ...
    def is_float(self) -> bool: ...
    def is_int(self) -> bool: ...
    def set_float(self, arg0: float) -> None: ...
    def set_int(self, arg0: int) -> None: ...
    def set_scope(self, arg0) -> None: ...
    def set_string_list(self, arg0: list[str]) -> None: ...
    def set_vocab(self, arg0: dict[str, int]) -> None: ...

class XPUPlace:
    def __init__(self, arg0: int) -> None: ...

class XpuConfig:
    context: capsule
    context_gm_size: int
    conv_autotune_file: str
    conv_autotune_file_writeback: bool
    conv_autotune_level: int
    device_id: int
    fc_autotune_file: str
    fc_autotune_file_writeback: bool
    fc_autotune_level: int
    gemm_compute_precision: int
    l3_autotune_size: int
    l3_ptr: capsule
    l3_size: int
    quant_post_dynamic_activation_method: int
    quant_post_dynamic_op_types: list[str]
    quant_post_dynamic_weight_precision: int
    quant_post_static_gelu_out_threshold: float
    stream: capsule
    transformer_encoder_adaptive_seqlen: bool
    transformer_softmax_optimize_level: int
    def __init__(self) -> None: ...

class ZeroCopyTensor:
    def __init__(self, *args, **kwargs) -> None: ...
    @overload
    def copy_from_cpu(self, arg0: numpy.ndarray[numpy.int8]) -> None: ...
    @overload
    def copy_from_cpu(self, arg0: numpy.ndarray[numpy.uint8]) -> None: ...
    @overload
    def copy_from_cpu(self, arg0: numpy.ndarray[numpy.int32]) -> None: ...
    @overload
    def copy_from_cpu(self, arg0: numpy.ndarray[numpy.int64]) -> None: ...
    @overload
    def copy_from_cpu(self, arg0: numpy.ndarray[numpy.float32]) -> None: ...
    @overload
    def copy_from_cpu(self, arg0: numpy.ndarray[float16]) -> None: ...
    @overload
    def copy_from_cpu(self, arg0: numpy.ndarray[numpy.float64]) -> None: ...
    @overload
    def copy_from_cpu(self, arg0: numpy.ndarray[bool]) -> None: ...
    @overload
    def copy_from_cpu(self, arg0: list[str]) -> None: ...
    def copy_to_cpu(self) -> numpy.ndarray: ...
    def lod(self) -> list[list[int]]: ...
    @overload
    def reshape(self, arg0: list[int]) -> None: ...
    @overload
    def reshape(self, arg0: int) -> None: ...
    def set_lod(self, arg0: list[list[int]]) -> None: ...
    def shape(self) -> list[int]: ...
    def type(self) -> PaddleDType: ...

class _Profiler:
    def __init__(self, *args, **kwargs) -> None: ...
    def create(self, arg0: list[str]) -> _Profiler: ...
    def is_cnpapi_supported(self) -> bool: ...
    def is_cupti_supported(self) -> bool: ...
    def is_xpti_supported(self) -> bool: ...
    def prepare(self) -> None: ...
    def start(self) -> None: ...
    def stop(self) -> _ProfilerResult: ...

class _ProfilerResult:
    def __init__(self) -> None: ...
    def get_data(self, *args, **kwargs): ...
    def get_extra_info(self) -> dict[str, str]: ...
    def get_span_indx(self) -> int: ...
    def get_version(self) -> str: ...
    def save(self, arg0: str, arg1: str) -> None: ...

class _RecordEvent:
    def __init__(self, arg0: str, arg1) -> None: ...
    def end(self) -> None: ...

class _Scope:
    def __init__(self, *args, **kwargs) -> None: ...
    def drop_kids(self) -> None: ...
    def erase(self, names: list[str]) -> None: ...
    def find_var(self, name: str) -> Variable: ...
    def new_scope(self) -> _Scope: ...
    def raw_address(self) -> int: ...
    def size(self) -> int: ...
    def var(self, name: str) -> Variable: ...

class finfo:
    def __init__(self, arg0) -> None: ...
    @property
    def bits(self) -> int: ...
    @property
    def dtype(self) -> str: ...
    @property
    def eps(self) -> float: ...
    @property
    def max(self) -> float: ...
    @property
    def min(self) -> float: ...
    @property
    def resolution(self) -> float: ...
    @property
    def smallest_normal(self) -> float: ...
    @property
    def tiny(self) -> float: ...

class iinfo:
    def __init__(self, arg0) -> None: ...
    @property
    def bits(self) -> int: ...
    @property
    def dtype(self) -> str: ...
    @property
    def max(self) -> int: ...
    @property
    def min(self) -> int: ...

class mt19937_64:
    def __init__(self, *args, **kwargs) -> None: ...

class task:
    def __init__(self, *args, **kwargs) -> None: ...
    def is_completed(self) -> bool: ...
    def is_sync(self) -> bool: ...
    def synchronize(self) -> None: ...
    def wait(self, timeout: datetime.timedelta = ...) -> bool: ...

@overload
def Load(arg0: str, arg1) -> Layer: ...
@overload
def Load(arg0: str, arg1) -> Layer: ...
def Scope() -> _Scope: ...
def __unittest_throw_exception__() -> None: ...
def apply_pass(arg0: ProgramDesc, arg1: ProgramDesc, arg2: object, arg3: dict[str, object], arg4: dict[str, str]) -> dict[str, object]: ...
def autotune_status() -> dict: ...
def broadcast_shape(arg0: list[int], arg1: list[int]) -> list[int]: ...
def build_adjacency_list(*args, **kwargs): ...
def call_decomp(arg0: pir.Operation) -> list: ...
def call_vjp(arg0: pir.Operation, arg1: list[list[pir.Value]], arg2: list[list[pir.OpResult]], arg3: list[list[pir.OpResult]], arg4: list[list[bool]]) -> list: ...
def clear_device_manager() -> None: ...
def clear_executor_cache() -> None: ...
def clear_gradients(arg0, arg1: bool) -> None: ...
def clear_kernel_factory() -> None: ...
def clear_low_precision_op_list() -> None: ...
def contains_spmd_rule(arg0: str) -> bool: ...
def convert_to_mixed_precision_bind(model_file: str, params_file: str, mixed_model_file: str, mixed_params_file: str, mixed_precision: AnalysisConfig.Precision, backend: PaddlePlace, keep_io_types: bool = ..., black_list: set[str] = ..., white_list: set[str] = ...) -> None: ...
def copy_tensor(arg0: PaddleInferTensor, arg1: PaddleInferTensor) -> None: ...
def create_empty_tensors_with_op_results(*args, **kwargs): ...
def create_empty_tensors_with_var_descs(*args, **kwargs): ...
def create_or_get_global_tcp_store() -> Store: ...
@overload
def create_paddle_predictor(config: AnalysisConfig) -> PaddlePredictor: ...
@overload
def create_paddle_predictor(config: NativeConfig) -> PaddlePredictor: ...
def create_predictor(arg0: AnalysisConfig) -> PaddleInferPredictor: ...
@overload
def create_py_reader(arg0: LoDTensorBlockingQueue, arg1: list[str], arg2: list[list[int]], arg3, arg4: list[bool], arg5, arg6: bool, arg7: bool, arg8: bool) -> MultiDeviceFeedReader: ...
@overload
def create_py_reader(arg0: OrderedMultiDeviceLoDTensorBlockingQueue, arg1: list[str], arg2: list[list[int]], arg3, arg4: list[bool], arg5, arg6: bool, arg7: bool, arg8: bool) -> OrderedMultiDeviceFeedReader: ...
def default_cpu_generator() -> Generator: ...
def default_cuda_generator(arg0: int) -> Generator: ...
def default_custom_device_generator(arg0: CustomPlace) -> Generator: ...
def default_xpu_generator(arg0: int) -> Generator: ...
def device_memory_stat_current_value(arg0: str, arg1: int) -> int: ...
def device_memory_stat_peak_value(arg0: str, arg1: int) -> int: ...
@overload
def diff_tensor_shape(arg0, arg1, arg2: int) -> object: ...
@overload
def diff_tensor_shape(arg0, arg1: list[int], arg2: int) -> object: ...
def disable_autotune() -> None: ...
def disable_layout_autotune() -> None: ...
def disable_memory_recorder() -> None: ...
def disable_op_info_recorder() -> None: ...
def disable_profiler(arg0: EventSortingKey, arg1: str) -> None: ...
def disable_signal_handler() -> None: ...
def dygraph_partial_grad(*args, **kwargs): ...
def dygraph_run_backward(arg0, arg1, arg2: bool, arg3: Tracer) -> None: ...
def eager_assign_group_by_size(tensors: object, is_sparse_gradient: list[bool], group_size_limits: list[int] = ..., tensor_indices: list[int] = ...) -> list[list[int]]: ...
def empty_var_name() -> str: ...
def enable_autotune() -> None: ...
def enable_layout_autotune() -> None: ...
def enable_memory_recorder() -> None: ...
def enable_op_info_recorder() -> None: ...
def enable_profiler(arg0: ProfilerState) -> None: ...
def eval_frame_no_skip_codes(py_codes: object) -> object: ...
def eval_frame_skip_file_prefix(py_codes: object) -> object: ...
def from_dlpack(*args, **kwargs): ...
def get_all_custom_device_type() -> list[str]: ...
def get_all_device_type() -> list[str]: ...
def get_all_op_names(lib: str = ...) -> list[str]: ...
def get_all_op_protos() -> list[bytes]: ...
def get_attrtibute_type(*args, **kwargs): ...
def get_available_custom_device() -> list[str]: ...
def get_available_device() -> list[str]: ...
def get_custom_device_count(arg0: str) -> int: ...
def get_fetch_variable(arg0: _Scope, arg1: str, arg2: int) -> object: ...
def get_float_stats() -> dict[str, float]: ...
def get_grad_op_desc(*args, **kwargs): ...
def get_int_stats() -> dict[str, int]: ...
def get_low_precision_op_list() -> dict: ...
def get_num_bytes_of_data_type(arg0: PaddleDType) -> int: ...
def get_op_attrs_default_value(arg0: bytes) -> dict[str, Variant]: ...
def get_op_extra_attrs(arg0: str) -> dict[str, Variant]: ...
def get_op_version_map() -> dict[str, OpVersion]: ...
def get_pass(*args, **kwargs): ...
def get_phi_spmd_rule(arg0: str) -> SpmdRule: ...
def get_promote_dtype(*args, **kwargs): ...
def get_random_seed_generator(arg0: str) -> Generator: ...
def get_serialize_comile_key(arg0: int) -> None: ...
def get_spmd_rule(arg0: str) -> SPMDRuleBase: ...
def get_trt_compile_version() -> tuple[int, int, int]: ...
def get_trt_runtime_version() -> tuple[int, int, int]: ...
def get_variable_tensor(*args, **kwargs): ...
def get_version() -> str: ...
def globals() -> GlobalVarGetterSetterRegistry: ...
def grad_var_suffix() -> str: ...
def graph_num(arg0) -> int: ...
def graph_safe_remove_nodes(arg0, arg1) -> None: ...
def has_circle(arg0) -> bool: ...
def has_comp_grad_op_maker(arg0: str) -> bool: ...
def has_custom_vjp(arg0: pir.Operation) -> bool: ...
def has_decomp(arg0: pir.Operation) -> bool: ...
def has_empty_grad_op_maker(arg0: str) -> bool: ...
def has_grad_op_maker(arg0: str) -> bool: ...
def has_infer_inplace(arg0: str) -> bool: ...
def has_non_empty_grad_op_maker(arg0: str) -> bool: ...
def has_vjp(arg0: pir.Operation) -> bool: ...
def host_memory_stat_current_value(arg0: str, arg1: int) -> int: ...
def host_memory_stat_peak_value(arg0: str, arg1: int) -> int: ...
def infer_no_need_buffer_slots(arg0: str, arg1: dict[str, list[str]], arg2: dict[str, list[str]], arg3: dict[str, Variant]) -> set[str]: ...
def init_default_kernel_signatures() -> None: ...
def init_devices() -> None: ...
def init_gflags(arg0: list[str]) -> bool: ...
def init_glog(arg0: str) -> None: ...
def init_lod_tensor_blocking_queue(arg0: Variable, arg1: int, arg2: bool) -> object: ...
def init_memory_method() -> None: ...
def init_tensor_operants() -> None: ...
def is_bfloat16_supported(arg0: CPUPlace) -> bool: ...
def is_compiled_with_avx() -> bool: ...
def is_compiled_with_brpc() -> bool: ...
def is_compiled_with_cinn() -> bool: ...
def is_compiled_with_cuda() -> bool: ...
def is_compiled_with_custom_device(arg0: str) -> bool: ...
def is_compiled_with_dist() -> bool: ...
def is_compiled_with_distribute() -> bool: ...
def is_compiled_with_ipu() -> bool: ...
def is_compiled_with_mkldnn() -> bool: ...
def is_compiled_with_mpi() -> bool: ...
def is_compiled_with_mpi_aware() -> bool: ...
def is_compiled_with_nccl() -> bool: ...
def is_compiled_with_rocm() -> bool: ...
def is_compiled_with_xpu() -> bool: ...
def is_cuda_graph_capturing() -> bool: ...
def is_float16_supported(arg0: CPUPlace) -> bool: ...
def is_profiler_enabled() -> bool: ...
def is_run_with_cinn() -> bool: ...
def kAutoParallelSuffix() -> str: ...
def kControlDepVarName() -> str: ...
def kEmptyVarName() -> str: ...
def kGradVarSuffix() -> str: ...
def kNewGradSuffix() -> str: ...
def kNoneProcessMeshIndex() -> int: ...
def kTempVarName() -> str: ...
def kZeroVarSuffix() -> str: ...
def load_lod_tensor(arg0, arg1: str) -> int: ...
def load_lod_tensor_from_memory(arg0, arg1: str) -> None: ...
def load_op_meta_info_and_register_op(arg0: str) -> None: ...
def load_profiler_result(arg0: str) -> _ProfilerResult: ...
def load_selected_rows(arg0, arg1: str) -> int: ...
def load_selected_rows_from_memory(arg0, arg1: str) -> None: ...
def need_type_promotion(arg0, arg1) -> bool: ...
def op_support_gpu(arg0: str) -> bool: ...
def op_supported_infos(arg0: str, arg1) -> tuple[set[str], set[str], set[str]]: ...
def paddle_dtype_size(arg0: PaddleDType) -> int: ...
def paddle_tensor_to_bytes(arg0: PaddleTensor) -> bytes: ...
def parse_safe_eager_deletion_skip_vars(arg0: ProgramDesc, arg1: bool) -> set[str]: ...
def prune(*args, **kwargs): ...
def prune_backward(*args, **kwargs): ...
def register_pass(arg0: str, arg1: object) -> None: ...
def register_subgraph_pass(arg0: str) -> None: ...
def reset_profiler() -> None: ...
def reshard(*args, **kwargs): ...
def run_cmd(cmd: str, time_out: int = ..., sleep_inter: int = ...) -> str: ...
def save_lod_tensor(arg0, arg1: str) -> int: ...
def save_lod_tensor_to_memory(arg0) -> bytes: ...
def save_op_version_info(arg0) -> None: ...
def save_selected_rows(arg0, arg1: str) -> int: ...
def save_selected_rows_to_memory(arg0) -> bytes: ...
def set_autotune_range(arg0: int, arg1: int) -> None: ...
def set_checked_op_list(arg0: str) -> None: ...
def set_current_thread_name(arg0: str) -> bool: ...
def set_eval_frame(callback: object) -> object: ...
@overload
def set_feed_variable(arg0: _Scope, arg1, arg2: str, arg3: int) -> None: ...
@overload
def set_feed_variable(arg0: _Scope, arg1: list[str], arg2: str, arg3: int) -> None: ...
def set_nan_inf_debug_path(arg0: str) -> None: ...
def set_nan_inf_stack_limit(arg0: int) -> None: ...
def set_num_threads(arg0: int) -> None: ...
def set_printoptions(**kwargs) -> None: ...
def set_random_seed_generator(arg0: str, arg1: int) -> Generator: ...
def set_skipped_op_list(arg0: str) -> None: ...
def set_tracer_option(arg0: TracerOption) -> None: ...
def set_variable(arg0: _Scope, arg1, arg2: str) -> None: ...
def shell_execute_cmd(cmd: str, time_out: int = ..., sleep_inter: int = ..., redirect_stderr: bool = ...) -> list[str]: ...
def size_of_dtype(arg0: VarDesc.VarType) -> int: ...
def sot_set_with_graph(py_codes: object) -> object: ...
def sot_setup_codes_with_graph(py_codes: object) -> object: ...
def start_imperative_gperf_profiler() -> None: ...
def stop_imperative_gperf_profiler() -> None: ...
def supports_bfloat16() -> bool: ...
def supports_bfloat16_fast_performance() -> bool: ...
def supports_int8() -> bool: ...
def supports_vnni() -> bool: ...
def topology_sort(*args, **kwargs): ...
def touch_dist_mapper() -> str: ...
def update_autotune_status() -> None: ...
def use_layout_autotune() -> bool: ...
@overload
def varbase_copy(arg0, arg1, arg2, arg3: bool) -> None: ...
@overload
def varbase_copy(arg0, arg1, arg2, arg3: bool) -> None: ...
@overload
def varbase_copy(arg0, arg1, arg2, arg3: bool) -> None: ...
@overload
def varbase_copy(arg0, arg1, arg2, arg3: bool) -> None: ...
@overload
def varbase_copy(arg0, arg1, arg2, arg3: bool) -> None: ...
@overload
def varbase_copy(arg0, arg1, arg2, arg3: bool) -> None: ...
def wait_device(arg0) -> None: ...
