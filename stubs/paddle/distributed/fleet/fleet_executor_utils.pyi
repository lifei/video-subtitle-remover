from _typeshed import Incomplete
from paddle.distributed.fleet.meta_optimizers.common import OP_ROLE_KEY as OP_ROLE_KEY, OpRole as OpRole
from paddle.framework import core as core
from paddle.static import Program as Program

class TaskNode:
    id: Incomplete
    rank: Incomplete
    max_run_times: Incomplete
    node_type: Incomplete
    program: Incomplete
    lazy_initialize: Incomplete
    cond_var_name: Incomplete
    vars_to_dtype: Incomplete
    vars_to_shape: Incomplete
    run_pre_steps: Incomplete
    run_at_offset: Incomplete
    node: Incomplete
    upstreams: Incomplete
    downstreams: Incomplete
    def __init__(self, rank, max_run_times, role: Incomplete | None = None, node_type: Incomplete | None = None, task_id: int = 0, ops: Incomplete | None = None, program: Incomplete | None = None, lazy_initialize: bool = False, cond_var_name: Incomplete | None = None, vars_to_dtype: Incomplete | None = None, vars_to_shape: Incomplete | None = None) -> None: ...
    def task_node(self): ...
    def set_program(self, program) -> None: ...
    def get_program(self): ...
    def set_run_pre_steps(self, steps) -> None: ...
    def set_run_at_offset(self, offset) -> None: ...
    def add_upstream_task(self, upstream, buffer_size: int = 2, depend_type=...) -> None: ...
    def add_downstream_task(self, downstream, buffer_size: int = 2, depend_type=...) -> None: ...
    def task_id(self): ...

class CoordSys:
    dp_degree: Incomplete
    pp_degree: Incomplete
    sharding_degree: Incomplete
    mp_degree: Incomplete
    def __init__(self, dist_opt) -> None: ...
    def coord_to_rank(self, coord): ...
    def rank_to_coord(self, rank): ...

class FleetExecutorUtils:
    dist_strategy: Incomplete
    rank: Incomplete
    nrank: Incomplete
    max_run_times: Incomplete
    is_auto_parallel: Incomplete
    num_of_functionality: int
    coord_sys: Incomplete
    coord: Incomplete
    def __init__(self, dist_strategy: Incomplete | None = None, rank: Incomplete | None = None, nrank: Incomplete | None = None, max_run_times: Incomplete | None = None) -> None: ...
    def is_optimizer_op(self, op_role): ...
    def is_lr_sched_op(self, op_role): ...
    def is_forward_op(self, op_role): ...
    def is_backward_op(self, op_role): ...
    def split_program_to_op_list(self, program): ...
    def convert_op_list_to_program(self, op_list, complete_program): ...
    def build_1f1b_dependency(self, task_node_map): ...
    def construct_task_nodes_1f1b(self, program_map): ...
    def task_id_to_rank(self): ...
    def construct_task_nodes_1f1b_op_list(self, op_list_map): ...

def run1f1b(program, rank, max_run_times, dist_opt, nrank, with_standalone_executor: bool = False): ...
def origin(program, rank): ...
