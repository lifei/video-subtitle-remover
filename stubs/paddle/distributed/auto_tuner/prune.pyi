from _typeshed import Incomplete
from paddle.distributed.launch.main import ctx as ctx

logger: Incomplete

def log_pruned_info(cur_cfg, pruned_reason) -> None: ...
def same_cfgs_beside(attr, cur_cfg, history_cfgs=[]): ...
def same_cfgs_beside_sharding_overlap(tuner_cfg, cur_cfg, history_cfgs=[]): ...
def register_prune(func): ...
def register_prune_history(func): ...
def prune_by_mp(tuner_cfg, cur_cfg, history_cfgs=[]): ...
def prune_by_pp(tuner_cfg, cur_cfg, history_cfgs=[]): ...
def prune_by_vpp(tuner_cfg, cur_cfg, history_cfgs=[]): ...
def prune_by_vpp_history(tuner_cfg, cur_cfg, history_cfgs=[]): ...
def prune_by_mbs(tuner_cfg, cur_cfg, history_cfgs=[]): ...
def prune_by_mbs_history(tuner_cfg, cur_cfg, history_cfgs=[]): ...
def prune_by_sharding(tuner_cfg, cur_cfg, history_cfgs=[]): ...
def prune_by_sharding_history(tuner_cfg, cur_cfg, history_cfgs=[]): ...
def prune_by_recompute(tuner_cfg, cur_cfg, history_cfgs=[]): ...
def prune_by_recompute_history(tuner_cfg, cur_cfg, history_cfgs=[]): ...
def prune_by_num_gpus(tuner_cfg, cur_cfg, history_cfgs=[]): ...
def prune_by_memory_estimation(tuner_cfg, cur_cfg, history_cfgs=[]): ...
def prune_by_sharding_overlap(tuner_cfg, cur_cfg, history_cfgs=[]): ...
