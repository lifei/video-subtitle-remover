from _typeshed import Incomplete
from paddle.base.framework import generate_control_dev_var_name as generate_control_dev_var_name
from paddle.distributed.io import is_persistable as is_persistable
from paddle.framework import core as core

OP_NAME_SCOPE: str
CLIP_OP_NAME_SCOPE: str
STEP_COUNTER: str
LEARNING_RATE_DECAY_COUNTER: str
OP_ROLE_VAR_ATTR_NAME: Incomplete
RPC_OP_ROLE_ATTR_NAME: Incomplete
RPC_OP_ROLE_ATTR_VALUE: Incomplete
op_role: Incomplete
op_role_attr_name: Incomplete
LR_SCHED_OP_ROLE_ATTR_VALUE: Incomplete
OPT_OP_ROLE_ATTR_VALUE: Incomplete
backward: Incomplete
OP_DEVICE_KEY: Incomplete
DEVICE_LIST: Incomplete
COMMUNICATE_OPS_TYPE: Incomplete
SPARSE_OP_LIST: Incomplete
SPARSE_OP_TYPE_DICT: Incomplete
SPARSE_GRAD_OP_TYPE_DICT: Incomplete
DEFAULT_DEVICE: str
DATA_NORM_NAME: Incomplete
DATA_NORM_GRAD_NAME: Incomplete

def logger_config(log_path, logging_name): ...

ps_log_root_dir: str
logger: Incomplete

class DistributedMode:
    SYNC: int
    ASYNC: int
    HALF_ASYNC: int
    GEO: int
    FL: int
    NU: int

class TrainerRuntimeConfig:
    mode: Incomplete
    runtime_configs: Incomplete
    def __init__(self, valid_strategy) -> None: ...
    def get_communicator_flags(self): ...

def get_lr_ops(program): ...
def get_optimize_ops(_program, remote_sparse=[]): ...
def get_datanorm_ops(_program): ...
def get_dist_env(): ...
def get_role_id(role_maker): ...
def get_ps_endpoint(role_maker): ...
def get_ps_endpoints(role_maker): ...
def get_heter_worker_endpoint(role_maker): ...
def get_trainer_endpoint(role_maker): ...
def get_trainer_endpoints(role_maker): ...
def get_previous_stage_trainers(role_maker): ...
def is_distributed_sparse_op(op): ...
def get_sparse_tablename(op): ...
def is_sparse_op(op): ...
def get_sparse_tablenames(programs, is_distributed): ...
def get_trainers(role_maker): ...
def get_dense_send_context(program, send_ctx, idx, merged_dense_pairs, trainer_id, split_dense_table: bool = False): ...
def get_geo_trainer_send_context(attrs): ...
def get_the_one_send_context(attrs, split_dense_table: bool = False, ep_list: Incomplete | None = None): ...
def find_heter_ops(program, default_device: str = 'cpu'): ...
def union_forward_gradient_op(program_block_ops_list): ...
def find_block_joints(program, program_block_ops_list, heter_ops): ...
def find_ops_list_input_output(program, ops_list): ...
def find_entrance_exit_private(program, program_block_ops_list): ...
def entrance_exit_check(program, program_block_ops_list, block_var_detail, heter_ops): ...
def delete_block_useless_exit(program, program_block_ops_list, block_var_detail): ...
def get_communicate_var_info(program, block_index, entrance_var_list, type: str = 'forward'): ...
def add_vars_by_var_list(var_name_list, origin_program, program, block) -> None: ...
def get_varlist_from_op_map(var_map): ...
def screen_persistables(program, var_list): ...
def block_append_op(program, origin_program, block, op): ...
def get_next_stage_trainers(role_maker): ...
def insert_communicate_op(orign_program, role_maker, heter_block, stage_id, first_op_index, block_var_detail, device, is_forward: bool = True): ...
def get_the_one_recv_context(context, is_dense: bool = True, split_dense_table: bool = False): ...

dtype_to_size: Incomplete

def get_var_mem_size(var): ...

class MergedVariable:
    merged_var: Incomplete
    ordered_vars: Incomplete
    offsets: Incomplete
    def __init__(self, merged, ordered, offsets) -> None: ...

def build_var_distributed(context) -> None: ...
def get_param_grads(origin_program): ...
def delete_ops(block, ops) -> None: ...
def find_send_op(program): ...
def find_op_input_output(program, block, op): ...
def add_send_op(program, block, _vars): ...
def get_vars_name_in_block(block): ...
def delete_trainer_useless_var(program, static_var): ...
def create_backward_block(program, origin_program, bp_ops_list, block_var_detail): ...
def is_backward_op(op): ...
def is_forward_op(op): ...
def is_push_sparse_op(op): ...
def get_distributed_push_sparse_op_list(block): ...
def get_bp_op_list(block): ...
def delete_same_ops(block, ops) -> None: ...
def check_program(program) -> None: ...
def debug_program(file, program) -> None: ...
def is_distributed_env(): ...
