from .amp_lists import AutoMixedPrecisionListsBF16 as AutoMixedPrecisionListsBF16
from .amp_utils import cast_model_to_bf16 as cast_model_to_bf16, cast_parameters_to_bf16 as cast_parameters_to_bf16, rewrite_program_bf16 as rewrite_program_bf16
from _typeshed import Incomplete
from paddle.base import core as core, default_main_program as default_main_program, program_guard as program_guard, unique_name as unique_name

class OptimizerWithMixedPrecision:
    def __init__(self, optimizer, amp_lists, use_pure_bf16, use_bf16_guard) -> None: ...
    def backward(self, loss, startup_program: Incomplete | None = None, parameter_list: Incomplete | None = None, no_grad_set: Incomplete | None = None, callbacks: Incomplete | None = None): ...
    def amp_init(self, place, scope: Incomplete | None = None, test_program: Incomplete | None = None, use_bf16_test: bool = False) -> None: ...
    def apply_gradients(self, params_grads): ...
    def apply_optimize(self, loss, startup_program, params_grads): ...
    def minimize(self, loss, startup_program: Incomplete | None = None, parameter_list: Incomplete | None = None, no_grad_set: Incomplete | None = None): ...

def decorate_bf16(optimizer, amp_lists: Incomplete | None = None, use_pure_bf16: bool = False, use_bf16_guard: Incomplete | None = None): ...
