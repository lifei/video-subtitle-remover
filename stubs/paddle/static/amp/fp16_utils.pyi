import paddle
from .fp16_lists import AutoMixedPrecisionLists as AutoMixedPrecisionLists, black_list as black_list, get_low_precision_dtypestr as get_low_precision_dtypestr
from _typeshed import Incomplete
from collections.abc import Generator
from dataclasses import dataclass
from paddle.base import core as core, framework as framework, global_scope as global_scope
from paddle.base.log_helper import get_logger as get_logger
from paddle.base.wrapped_decorator import signature_safe_contextmanager as signature_safe_contextmanager

@dataclass
class AmpOptions:
    enable: bool
    custom_white_list: list[str] | None
    custom_black_list: list[str] | None
    level: str
    dtype: str
    use_promote: bool

DEFAULT_AMP_OPTIONS: Incomplete

def find_true_prev_op(ops, cur_op, var_name): ...
def find_true_post_op(ops, cur_op, var_name, search_all: bool = False): ...
def find_op_index(block_desc, cur_op_desc): ...
def fp16_guard() -> Generator[None]: ...

FLOAT_TYPES: Incomplete
SUPPORT_FLOAT_TYPES: Incomplete

def set_var_dst_dtype(op, var_names, block, global_block, dtype, need_set_dtype): ...
def set_param_dtype(program, dtype, amp_lists, use_fp16_guard, level): ...
def op_need_keep_fp32(op, amp_lists, use_fp16_guard, params_list): ...
def get_promote_dtype(op, amp_dtype, block): ...
def get_amp_dst_dtype(op, amp_dtype, level, block, amp_lists, keep_fp32_ops, keep_fp16_ops): ...
def process_op_input_and_outputs(op, block, global_block, dtype): ...
def map_block(block, fn, parent_op: Incomplete | None = None) -> None: ...
def prepare_op_amp_options(program: paddle.static.Program, amp_records: dict[int, list[tuple[AmpOptions, int, int]]], global_amp_options: AmpOptions): ...
def cast_model_to_fp16(program, amp_lists: Incomplete | None = None, use_fp16_guard: bool = True, dest_type=..., level: str = 'O2', use_promote: bool = False): ...
def cast_parameters_to_fp16(place, program, scope: Incomplete | None = None, to_fp16_var_names: Incomplete | None = None, dest_type=..., rewrite_master_weight: bool = False, master_weights={}) -> None: ...
def update_role_var_grad(main_prog, params_grads) -> None: ...
