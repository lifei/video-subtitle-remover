from . import utils as utils
from ...base.framework import IrGraph as IrGraph, IrNode as IrNode
from ...framework import core as core
from ...static import Program as Program, data as data, program_guard as program_guard, scope_guard as scope_guard
from ...utils import unique_name as unique_name
from ..log_helper import get_logger as get_logger
from .quant_config import SUPPORT_ACT_QUANTIZATION_OP_DICT as SUPPORT_ACT_QUANTIZATION_OP_DICT, SUPPORT_QUANTIZATION_OP_DICT as SUPPORT_QUANTIZATION_OP_DICT, SUPPORT_WEIGHT_QUANTIZATION_OP_DICT as SUPPORT_WEIGHT_QUANTIZATION_OP_DICT
from .utils import tqdm as tqdm
from _typeshed import Incomplete

class QuantizationTransformPass:
    create_var_map: Incomplete
    create_op_map: Incomplete
    def __init__(self, scope: Incomplete | None = None, place: Incomplete | None = None, weight_bits: int = 8, activation_bits: int = 8, activation_quantize_type: str = 'abs_max', weight_quantize_type: str = 'abs_max', window_size: int = 10000, moving_rate: float = 0.9, skip_pattern=['skip_quant'], quantizable_op_type=['conv2d', 'depthwise_conv2d', 'mul'], weight_quantize_func: Incomplete | None = None, act_quantize_func: Incomplete | None = None, weight_preprocess_func: Incomplete | None = None, act_preprocess_func: Incomplete | None = None, optimizer_func: Incomplete | None = None, executor: Incomplete | None = None, is_test: Incomplete | None = None) -> None: ...
    def apply(self, graph): ...

class QuantizationFreezePass:
    def __init__(self, scope, place, bias_correction: bool = False, weight_bits: int = 8, activation_bits: int = 8, round_type: str = 'round', weight_quantize_type: str = 'abs_max', quantizable_op_type: Incomplete | None = None) -> None: ...
    def apply(self, graph): ...

class ConvertToInt8Pass:
    def __init__(self, scope, place, quantizable_op_type: Incomplete | None = None) -> None: ...
    def apply(self, graph): ...

class TransformForMobilePass:
    def __init__(self) -> None: ...
    def apply(self, graph): ...

class OutScaleForTrainingPass:
    def __init__(self, scope: Incomplete | None = None, place: Incomplete | None = None, moving_rate: float = 0.9, is_test: Incomplete | None = None, scale_dict: Incomplete | None = None) -> None: ...
    def apply(self, graph): ...

class OutScaleForInferencePass:
    def __init__(self, scope: Incomplete | None = None) -> None: ...
    def apply(self, graph): ...

class AddQuantDequantPass:
    def __init__(self, scope: Incomplete | None = None, place: Incomplete | None = None, moving_rate: float = 0.9, quant_bits: int = 8, skip_pattern=['skip_quant'], quantizable_op_type=['elementwise_add', 'pool2d'], is_test: Incomplete | None = None, scale_dict: Incomplete | None = None) -> None: ...
    def apply(self, graph): ...

class InsertQuantizeLinear:
    quant_bits: Incomplete
    quant_axis: Incomplete
    channel_wise: Incomplete
    def __init__(self, place, scope, quant_bits: int = 8, quant_axis: int = -1, channel_wise: bool = False, moving_rate: float = 0.9, is_test: bool = True, scale_dict: Incomplete | None = None) -> None: ...
    def insert_quant_op(self, graph, var_node, var_name: Incomplete | None = None, scale_var_node: Incomplete | None = None, op_role=...): ...
    def insert_dequant_op(self, graph, var_node, scale_var_node, op_role): ...

class QuantizationTransformPassV2(QuantizationTransformPass):
    create_var_map: Incomplete
    create_op_map: Incomplete
    def __init__(self, scope: Incomplete | None = None, place: Incomplete | None = None, weight_bits: int = 8, activation_bits: int = 8, activation_quantize_type: str = 'abs_max', weight_quantize_type: str = 'abs_max', window_size: int = 10000, moving_rate: float = 0.9, skip_pattern=['skip_quant'], quantizable_op_type=['conv2d', 'depthwise_conv2d', 'mul'], weight_quantize_func: Incomplete | None = None, act_quantize_func: Incomplete | None = None, weight_preprocess_func: Incomplete | None = None, act_preprocess_func: Incomplete | None = None, optimizer_func: Incomplete | None = None, executor: Incomplete | None = None, is_test: Incomplete | None = None) -> None: ...
    dequantized_vars: Incomplete
    persistable_vars: Incomplete
    processed_vars: Incomplete
    persistable_cast_output_vars: Incomplete
    def apply(self, graph): ...

class AddQuantDequantPassV2:
    persistable_vars: Incomplete
    def __init__(self, scope: Incomplete | None = None, place: Incomplete | None = None, moving_rate: float = 0.9, quant_bits: int = 8, skip_pattern=['skip_quant'], quantizable_op_type=['elementwise_add', 'pool2d'], is_test: Incomplete | None = None, scale_dict: Incomplete | None = None) -> None: ...
    def apply(self, graph): ...

class ReplaceFakeQuantDequantPass:
    def __init__(self, scope, place, quant_bits: int = 8) -> None: ...
    def apply(self, graph): ...

class QuantWeightPass:
    def __init__(self, scope, place, bias_correction: bool = False, quant_bits: int = 8, save_int_weight: bool = True) -> None: ...
    def apply(self, graph) -> None: ...

class AddQuantDequantForInferencePass:
    def __init__(self, scope, place, quant_bits: int = 8, quantizable_op_type=[], calibration_range_dict: Incomplete | None = None, only_observer: bool = True) -> None: ...
    def apply(self, graph): ...

class AddQuantDequantForResidual:
    def __init__(self, scope, place, quant_bits: int = 8, is_test: bool = True) -> None: ...
    def apply(self, graph) -> None: ...
