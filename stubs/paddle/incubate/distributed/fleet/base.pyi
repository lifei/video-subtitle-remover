import abc
from _typeshed import Incomplete
from paddle import base as base
from paddle.base.executor import Executor as Executor
from paddle.distributed.fleet.base.role_maker import RoleMakerBase as RoleMakerBase
from paddle.optimizer import SGD as SGD
from paddle.static.amp.decorator import OptimizerWithMixedPrecision as OptimizerWithMixedPrecision

class Mode:
    TRANSPILER: int
    PSLIB: int
    COLLECTIVE: int

class Fleet(metaclass=abc.ABCMeta):
    def __init__(self, mode) -> None: ...
    def is_first_worker(self): ...
    def worker_index(self): ...
    def worker_num(self): ...
    def is_worker(self): ...
    def worker_endpoints(self, to_string: bool = False): ...
    def server_num(self): ...
    def server_index(self): ...
    def server_endpoints(self, to_string: bool = False): ...
    def is_server(self): ...
    def is_xpu(self): ...
    def split_files(self, files): ...
    def init(self, role_maker: Incomplete | None = None) -> None: ...
    def all_reduce_worker(self, input, output) -> None: ...
    def barrier_worker(self) -> None: ...
    @abc.abstractmethod
    def init_worker(self): ...
    @abc.abstractmethod
    def init_server(self, model_dir: Incomplete | None = None, **kwargs): ...
    @abc.abstractmethod
    def run_server(self): ...
    @abc.abstractmethod
    def stop_worker(self): ...
    @abc.abstractmethod
    def distributed_optimizer(self, optimizer, strategy: Incomplete | None = None): ...
    @abc.abstractmethod
    def save_inference_model(self, executor, dirname, feeded_var_names, target_vars, main_program: Incomplete | None = None, export_for_deployment: bool = True, legacy_format: bool = False): ...
    @abc.abstractmethod
    def save_persistables(self, executor, dirname, main_program: Incomplete | None = None): ...

class DistributedOptimizer(metaclass=abc.ABCMeta):
    def __init__(self, optimizer, strategy: Incomplete | None = None) -> None: ...
    @abc.abstractmethod
    def backward(self, loss, startup_program: Incomplete | None = None, parameter_list: Incomplete | None = None, no_grad_set: Incomplete | None = None, callbacks: Incomplete | None = None): ...
    @abc.abstractmethod
    def apply_gradients(self, params_grads): ...
    @abc.abstractmethod
    def minimize(self, losses, scopes: Incomplete | None = None, startup_programs: Incomplete | None = None, parameter_list: Incomplete | None = None, no_grad_set: Incomplete | None = None): ...
